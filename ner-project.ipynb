{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7809e102",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Dilru1/ner-project/blob/main/ner-project.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a87fa4",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) Systems\n",
    "\n",
    "Project Overview: Building and comparing RNN-based (LSTM) and Transformer-based (BERT) models for named entity recognition on the CONLL-03 dataset.\n",
    "\n",
    "* **GitHub Repository**: [https://github.com/Dilru1/ner-project.git](https://github.com/Dilru1/ner-project.git)\n",
    "* **Open in Colab**: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Dilru1/ner-project/blob/main/ner-project.ipynb)\n",
    "\n",
    "\n",
    "### Author\n",
    "* **DEHIWALAGE DON** Dilruwan (ENSAI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff7824",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6023d",
   "metadata": {},
   "source": [
    "## 0.1 Setup and Environment\n",
    "This project requires a Python environment with PyTorch, Transformers (Hugging Face), and Scikit-Learn installed. The following cell imports the necessary libraries and verifies the installed versions to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d813c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ensai/miniconda3/envs/torchgpu/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Library Versions ---\n",
      "Python:       3.13.9\n",
      "PyTorch:      2.9.1+cu128\n",
      "Transformers: 4.57.5\n",
      "Scikit-Learn: 1.8.0\n",
      "CUDA Available: True\n",
      "GPU Device:   NVIDIA RTX 1000 Ada Generation Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import sklearn\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer  #`transformers` provides the pre-trained DistilBERT model and tokenizer.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"--- Library Versions ---\")\n",
    "print(f\"Python:       {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch:      {torch.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"Scikit-Learn: {sklearn.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device:   {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "\n",
    "#project root \n",
    "project_root = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30efb8e6",
   "metadata": {},
   "source": [
    "## 0.2 Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "85b07cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f81a8",
   "metadata": {},
   "source": [
    "\n",
    "Before building the models, it is essential to understand the structure and characteristics of the CONLL-03 dataset. In this section, we will:\n",
    "\n",
    "1.  **Verify Dataset Splits:** Check the size of the training, validation, and test sets.\n",
    "2.  **Inspect Samples:** Visualize how sentences and named entity tags are structured (IOB format).\n",
    "3.  **Analyze Class Distribution:** Examine the frequency of each tag (PER, ORG, LOC, MISC) to detect potential class imbalances that might affect training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8f8a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 14041\n",
      "valid 3250\n",
      "test 3453\n"
     ]
    }
   ],
   "source": [
    "if \"COLAB_GPU\" in os.environ:\n",
    "    url = \"https://raw.githubusercontent.com/Dilru1/ner-project/main/data/conll03-iob-pos.json.gz\"\n",
    "    data_path = Path(\"conll03-iob-pos.json.gz\")\n",
    "    if not data_path.exists():\n",
    "        urllib.request.urlretrieve(url, data_path)\n",
    "else:\n",
    "    project_root = Path.cwd()\n",
    "    data_path = project_root / \"data\" / \"conll03-iob-pos.json.gz\"\n",
    "\n",
    "with gzip.open(data_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for fold in (\"train\", \"valid\", \"test\"):\n",
    "    print(fold, len(data[fold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f0ac1e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a arbitary sample of data\n",
    "sample_idx = 10\n",
    "sample = data['train'][sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "839a8017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHqCAYAAADLbQ06AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhPtJREFUeJzs3XdUFOf79/E3IIgVEbFr7KDSNRIQxa6xRo0x9oK9xYq9G1sUsRdUDGKCJnaj8RtbYmKJDRUFFQUbihQBkQ7z/MHD/FyxQEJZ4/U6x3PcmXt3rll29zPlvmd0FEVREEIIIYRW0s3vAoQQQgjxdhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtQiy1avXo2ZmVmeLKtPnz706dNHfXz+/HnMzMz49ddf82T5U6ZMoVmzZnmyrH/q5cuXTJ8+nYYNG2JmZsa3336b3yX955mZmbF69er8LiNLHj16hJmZGXv27PlHz/+Q1vW/rkB+FyDyx549e5g6dar62MDAACMjI8zMzHB2dqZLly4ULVr0Xy8nNDSUXbt20aJFC2rXrv2vXy8naXNtWbFx40b27t3LiBEjqFSpEtWrV39r22bNmvH48WN69+7NzJkzNeadP3+evn37snLlStq0aQNk/ny8bufOndjY2ABk2ngrUqQIderUYdCgQTRp0uSd69CnTx/+/vvvd7YBGDVqFKNHj35vuw/NwYMHiYiIoH///vldilaJjIxk3bp1/Pnnn4SEhFCkSBEqVKiAvb09I0aMoEiRItl6vcuXL/PXX3/Rr18/ihcvnktV5x4J6o/cmDFjqFixIikpKYSHh/P333+zcOFCtm3bxrp16zA3N1fbDh8+nCFDhmTr9Z89e8aaNWuoUKFCtsJwy5Yt2VrOP/Gu2ubPn4+2Xwb/3LlzWFtbM2rUqCw/Z9euXQwZMoQyZcpkqX3G5+N1lStX1njcsGFDOnXqhKIohISE8OOPPzJs2DA8PDxo1KjRW19/2LBhfPnll+rj69evs337doYNG0a1atXU6Xl1JOd9rl27hp6eXo693qFDh7hz506uBHWFChW4du0aBQr8s5/5nF7XrIqKiqJr167ExsbStWtXqlWrRlRUFLdu3eLHH3+kR48e2Q7qK1eusGbNGjp37ixBLT48jRs3xtLSUn08dOhQzp49y7BhwxgxYgSHDx/G0NAQgAIFCvzjL31WxcfHU6hQIQwMDHJ1Oe+jr6+fr8vPioiICGrUqJHl9jVr1iQoKAgPDw9mzJiRpee8/vl4mypVqtCpUyf1cevWrWnbti1eXl7vDOqGDRtqPC5YsCDbt2/H0dERe3v7LNWYlwoWLJhvy05MTERfXx9d3aydsdTR0flX9ebXuv7888/qxp6dnZ3GvNjY2A/iu5nT5By1yMTBwYERI0bw+PFjDhw4oE5/0znqv/76ix49elC/fn1sbW1p3bo1bm5uQPoh1Yy9palTp2JmZqZxzqxPnz60b98ePz8/evXqhbW1tfrc189RZ0hLS8PNzY2GDRtiY2PDsGHDePLkiUabZs2aMWXKlEzPffU131fbm85Rx8XFsXjxYpydnbGwsKB169Zs2bIl0563mZkZ8+bN49ixY7Rv3x4LCwvatWvHH3/88a63XRUREcG0adNwdHTE0tKSjh07snfvXnV+xvn6R48ecerUKbX2R48evfN1K1SoQKdOndi1axehoaFZquWfql69OsbGxjx48OBfv9bFixcZM2YMTZo0wcLCAmdnZxYuXEhCQkKmtkeOHKFt27ZYWlrSvn17fvvttzf+LX/55Re6dOmCra0tdnZ2dOjQge+///69tbx+3jbjO3H//n2mTJlC/fr1qVevHlOnTiU+Pv6dr9WnTx9OnTrF48eP1b9hRp0Zf+NffvmFFStW0KhRI6ytrYmNjSUqKoolS5bQoUMHtf5BgwYREBCg8fpvOkc9ZcoUbG1tCQ0NZcSIEdja2vLZZ5+xZMkSUlNTc2xdExISWLBgAfb29tja2jJs2DBCQ0OzdN77wYMH6OnpqadWXlW0aNFMGxBXr17FxcWFevXqYW1tTe/evbl06ZJG3UuXLgWgefPmWf6+aBPZoxZv1KlTJ9zc3Pjzzz/56quv3tjmzp07DB06FDMzM8aMGYOBgQH379/n8uXLQPqP9ZgxY1i1ahXdu3enXr16ABpbyVFRUQwePJh27drRsWNHTExM3lnX+vXr0dHRYfDgwURERPD999/Tv39/9u/fr+75Z0VWanuVoigMHz5cDfjatWtz+vRpli5dSmhoKNOmTdNof+nSJf73v//Rs2dPihQpwvbt2xkzZgwnT57E2Nj4rXUlJCTQp08fHjx4QK9evahYsSK//vorU6ZMISYmhn79+lG9enWWLl3KokWLKFu2LAMGDACgZMmS713v4cOHs3///izvVcfGxhIZGakxTUdH553rAPDixQtiYmIyHSL/J3799VcSEhLo0aMHJUqU4Nq1a3h7e/P06VNWrVqltjt16hTjxo2jVq1aTJgwgejoaKZPn57pMP9ff/3F+PHjcXBwYOLEiQDcu3ePy5cv069fv39U49ixY6lYsSLjx4/n5s2b/PTTT5QsWZJJkya99TnDhg3jxYsXPH36VO0P8Poh3XXr1qGvr4+LiwtJSUno6+sTGBjIsWPHaNOmDRUrViQ8PJydO3fSu3dvfvnll/ee1khNTcXFxQUrKytcXV05e/YsW7dupVKlSvTs2TNH1nXKlCkcOXKETp06YW1tzYULF7J82qxChQqkpqayf/9+Onfu/M62Z8+eZfDgwVhYWDBq1Ch0dHTYs2cP/fr144cffsDKyoqWLVsSHBzMoUOHmDp1qvrZzcr3RVtIUIs3Klu2LMWKFePhw4dvbfPXX3+RnJyMh4fHGz/0pUqVonHjxqxatQobGxuNQ6MZwsLCmDt3Ll9//XWW6oqOjubw4cNqR7c6deowduxYdu3aRd++fbO4dlmr7VXHjx/n3LlzjB07luHDhwPQq1cvxowZg5eXF71799YIpbt373L48GF1mr29PZ06deKXX36hd+/eb13Ozp07uXv3Lt999x0dO3YE4Ouvv6ZPnz64u7vTtWtXSpUqRadOnVi5ciVlypR5b+2vqlSpEh07dlTPVZcuXfqd7d907tTAwIDr169rTEtMTFQDPSQkBHd3d1JTU2ndunWWa3ubiRMnamyEde/enU8++QQ3NzdCQkIoX748AMuXL6dMmTL8+OOPauA5ODjQp08fKlSooD7/1KlTFC1alC1btuTYOdjatWuzcOFC9XFUVBQ///zzO4O6YcOGeHl5ERMT89a/YWJiIrt379ZYfzMzM44ePapxCLxTp058/vnn/Pzzz4wcOfKdtSYmJvL555+r7Xr06EHnzp35+eefsxTU71vXGzducOTIEfr166duwPbq1YupU6dm2ut/k65du7Jt2zamTJnCpk2baNCgAZ9++inOzs4UK1ZMbacoCnPmzMHe3p7Nmzejo6MDpH9f2rVrh7u7O1u3bsXc3Jw6depw6NAhWrRo8cY+F9pODn2LtypcuDAvX7586/yMThnHjx8nLS3tHy3DwMCALl26ZLn9F198odEbvU2bNpiamvL777//o+Vn1R9//IGenl6mw/EDBw5EUZRMh7UdHR01gtvc3JyiRYu+c8MnYzmmpqa0b99enaavr0+fPn2Ii4vjwoUL/3pdRowYQWpqKps2bXpv21mzZuHp6anxz8PDI1O7n3/+GQcHBxwcHOjatSvnzp1j0KBB6t7+v/FqSMXFxREZGYmtrS2KonDz5k0gvQf/7du3+eKLLzT2Shs0aECtWrU0Xq948eLEx8fz119//evaMry+oVm/fn2ioqKIjY39V6/7xRdfZDpSZGBgoIZ0amoqz58/p3DhwlStWlV9P96nR48eGo/r1auX5UPB71vX06dPA2QK/XdtoL6qVKlS7N+/n6+//pqYmBh8fHyYMGECDg4OrF27Vj3V5O/vT3BwMB06dOD58+dERkYSGRlJXFwcDg4OXLhw4R//Lmkb2aMWbxUXF/fOQ9Ft27blp59+YsaMGSxfvhwHBwdatmxJmzZtstzhpUyZMtnqOPbJJ59oPNbR0eGTTz7h8ePHWX6Nf+Lx48eULl0605C1jCFRry+/XLlymV7DyMiImJiY9y7nk08+yfT+ZSwnJCQk27W/7vW96nexsrLKUmey5s2b07t3b5KTk7l+/TobNmwgISEhy5+DdwkJCWHVqlWcOHGC6OhojXkZ4ZDxvrzpUPsnn3yiEWA9e/bkyJEjDB48mDJlytCwYUM+//xzGjdu/I9rzNirz5CxERsdHf2vhjm+ae8vLS0NLy8vfvjhBx49eqRxbrlEiRLvfc2CBQtmOgJmZGSU6b19m/eta0hICLq6uplqf/27+y6lS5dm7ty5zJkzh+DgYP788088PDxYtWoVpUuXplu3bgQHBwMwefLkt77OixcvMDIyyvJytZUEtXijp0+f8uLFi3eeYzQ0NGTHjh2cP3+eU6dOcfr0aQ4fPszOnTvZunVrlg4rZue88r+VmpqaZ8NN3rYcbRnyNXz4cA4cOICHhwctWrT4169XtmxZHB0dAXB2dsbY2Jh58+Zhb29Pq1at/vHrpqamMmDAAKKjoxk0aBDVqlWjcOHChIaGMmXKlH+0x2RiYsK+ffv4888/+eOPP/jjjz/Ys2cPX3zxBUuWLPlHdb5tg+Tf/r3f9P3YsGEDK1eupGvXrnzzzTcYGRmhq6vLwoULs7S8f/sdyK11fRMdHR2qVq1K1apVadKkCa1ateLAgQN069ZNXZ6rq+tbh34WLlw4x2vKDxLU4o32798PgJOT0zvb6erqqoc8p06dyoYNG1ixYgXnz5/H0dFRPW+UU+7fv6/xWFEU7t+/r9Eb/W17riEhIVSqVEl9nJ3aKlSowNmzZ4mNjdXYQ7p37546PydUqFCBW7dukZaWpvGDmLGc1/dm/qnKlSvTsWNHdu7cibW1dY685qu6d+/Otm3bcHd3p2XLlv/4c3D79m2Cg4NZsmQJX3zxhTr99cPWGe/Lm3qZv/6ZgfTDx82aNaNZs2akpaUxZ84cdu7cyYgRI7K15/dv/ZP35ejRo9jb22ucJwaIiYl5bye/vFC+fHnS0tJ49OgRVapUUae/6e+QHZUqVaJ48eKEhYWpjyG9J3jGRuLb5PTvUF6Tc9Qik7Nnz7Ju3ToqVqyodmh6k6ioqEzTMrZsk5KSAChUqBDAew/5ZtW+ffs0zvv9+uuvhIWFaRy2rFSpElevXlVrADh58mSmYVzZqa1x48akpqayY8cOjenbtm1DR0fnXx02fX05YWFhHD58WJ2WkpLC9u3bKVy4MJ9++mmOLAfS96pTUlLYvHlzjr1mhgIFCjBgwADu3r3L8ePH//HrZGysvLq3pigKXl5eGu3KlClDrVq12Ldvn0a/ir///pvbt29rtH3+/HmmZWRs6L36mckLhQoV4sWLF9l6jp6eXqa91yNHjuT6kLusyti4/+GHHzSme3t7Z+n5V69eJS4uLtP0a9euERUVRdWqVQGwsLCgcuXKbN269Y19aV4drZDxXc/ue60tZI/6I/fHH39w7949UlNTCQ8P5/z58/z111+UL1+e9evXv/OiB2vXruXixYs4OztToUIFIiIi+OGHHyhbtqw63Kly5coUL14cHx8fihQpQuHChbGystLYs80OIyMjevbsSZcuXdThWZ988onGELJu3bpx9OhRBg0axOeff86DBw84ePBgpsP42amtWbNm2Nvbs2LFCnXc619//cXx48fp169fjgxDgvQ90Z07dzJlyhRu3LhBhQoVOHr0KJcvX2batGk5clnXDBl71a+O0X5dxufjdXZ2du/9G3bp0oVVq1b9q8Pr1apVo3LlyixZsoTQ0FCKFi3K0aNH37hxNW7cOEaMGEGPHj3o0qULMTEx7Nixg1q1amn8kM+YMYPo6Gg+++wzypQpQ0hICN7e3tSuXfudl2HNDXXr1uXw4cMsWrQIS0tLChcu/N5rzDdp0oS1a9cydepUbG1tuX37NgcPHvzH36mclnGNge+//56oqCh1eFbGOeX37d3u37+fgwcP0qJFCywsLNDX1+fu3bvs3r2bggULMmzYMCB9A2vBggUMHjyY9u3b06VLF8qUKUNoaCjnz5+naNGibNiwAUh/nwFWrFhB27Zt0dfXp2nTph/MoXEJ6o9cxjhUfX19SpQoQa1atZg2bVqWrvWdcf3o3bt38/z5c4yNjWnQoAGjR49Wh1Ho6+uzePFi3NzcmDNnDikpKSxatOgf/6gMGzaMW7dusWnTJl6+fImDgwOzZ89Wt5gBGjVqxJQpU/D09GThwoVYWFiwYcOGTOcfs1Obrq4u69evZ9WqVRw+fJg9e/ZQoUIFXF1dGThw4D9alzcxNDRk+/btLFu2jL179xIbG0vVqlVZtGhRtnrHZ1XGuerXL3aR4dVxyq/Kyt/Q0NCQ3r17s3r1as6fP/+PrjSmr6/Phg0bWLBgARs3bqRgwYK0bNmSXr16ZRrS1KxZM9zc3Fi9ejXLly+nSpUqLFq0iH379nHnzh21XUZHuh9++IGYmBhMTU35/PPPGT16dI50fsuOnj174u/vz549e9i2bRsVKlR4b1APGzaM+Ph4Dh48yOHDh6lTpw4bN25k+fLleVT1+y1ZsoRSpUrxyy+/8Ntvv+Ho6MiKFSto06bNezuPdu/eHUNDQ86dO8eJEyeIjY3F2NiYhg0bMnToUOrUqaO2tbe3Z+fOnaxbtw5vb2/i4uIwNTXFysqK7t27q+2srKz45ptv8PHx4fTp06SlpXH8+PEPJqh1FG3p3SKEELmgU6dOlCxZEk9Pz/wu5aPm7+/PF198oXGNAJE1co5aCPGfkJycTEpKisa08+fPExAQQIMGDfKpqo/Tmy7v+v3336Orq5uj/Sw+FnLoWwjxnxAaGsqAAQPo2LEjpUuX5t69e/j4+GBqaprlK9+JnLF582b8/Pz47LPP0NPTU4fBde/e/Y3XGBDvJkEthPhPMDIyom7duvz0009ERkZSuHBhnJ2dmThxolYMW/qY2Nra8tdff7Fu3Tri4uIoV64co0ePVjuCieyRc9RCCCGEFpNz1EIIIYQWk6AWQgghtJico85DaWlppKSkoKur+8Ff0k4IIcQ/pygKaWlpFChQ4L3j9yWo81BKSkqm+/gKIYT4eFlaWr73IjAS1HkoY6vJ0tIyz+7iJIQQQvukpqZy/fr1LF0NT4I6D2Uc7tbT05OgFkIIkaXToNKZTAghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSohRBCCC0mQS2EEEJoMQlq8a9s2rSJ1q1bY25ujpmZGefPn1fnvXjxgtmzZ9OwYUMsLCxo1qwZR44cUedv3bqVli1bYmlpSfv27Tl+/Lg6b8+ePZiZmWn869SpEwCPHj3KNC/j36t1Zby2vb09w4cP58mTJ3nwjgghRM6ScdTiX0lKSqJJkyb89ttvPH78WJ2uKApDhgzh8uXLtG/fHgcHB0JCQkhJSQFg586dLFmyhE8//ZQhQ4awdu1axowZw6FDh6hatar6OiNGjKBGjRoAFC9eHICSJUvi5uamtrl8+TLe3t5YWVkBcO7cOZYvX06ZMmWYOXMmJ06c4MSJExQuXJjly5fn+nsihBA5SYJa/CujRo0C4MqVKxpBff78eS5fvky9evX47rvvSE5OpmDBgur833//HYD+/fvTokUL7t+/j4eHBzt37mTKlClqu/r162NnZ0ehQoXUaYULF6Zdu3bq4927dwPg4uICpG8kAJiYmODo6MiTJ084efIkRkZGOb36QgiR6+TQt8gVfn5+AISFhWFnZ4e1tTVdu3blzp07AJQqVQqAs2fP8vjxYy5fvgzA/fv3NV7HxcUFGxsbmjZtyv79+zMtJyAggL/++otKlSrRqlUrABwcHBg1ahT+/v40b96cdevW0aBBAyZPnpxr6yuEELlFglrkioxLpIaFhTF37lyGDh2Kn5+furc8YsQIqlWrhre3N82aNeP27dvA/+0NV65cmSlTprB+/XqmT59OZGQkU6dO5d69exrL2bZtGwADBgxQr5kbHBzMjh07qFixIqtXr6Zbt278/fffrFixIi9WXQghcpQEtcgVn3zyCQC1atWiU6dO6mHp4OBgAMqWLcvBgwfZv38/u3fvpn///gDUrVsXSD/kPWDAAJo2bUrfvn1p0KABqampBAYGqssIDQ3l0KFDlChRgi5duqjTjx8/zvPnz2nSpAmtWrViwIAB6nQhhPjQyDlq8a9cuHCB4OBgIiMjATh16hQPHjzgiy++oHLlyty8eZNt27YRFBQEgKOjI5Ae2Lt376ZatWoEBwezbds2SpYsSY8ePQCYPXs2hQoVombNmoSEhHD27FkKFiyoBjmAt7c3ycnJ9OzZU+McdpUqVQA4evQotWrV4s8//wTSNxqEEOJDo6NkHGsUuS41NRVfX19sbGz+M3fPmjJlCnv37s00/datWwQGBjJv3jx8fX0pWrQozs7OuLq6YmxszP379xk2bBiPHj2iQIEC2Nvb4+rqSrVq1QD44Ycf+PHHH3n06BG6urqYmZkxevRoHBwcAIiLi6NJkyYkJCRw8uRJTExMNJa/adMmfvrpJ54+fUrRokWxt7dn2rRplC5dOvffFCGEeI/s5IEEdR76Lwa1EEKI7MtOHsihb5Ernj59SlRUVL4tv0SJEpQtWzbfli+EEDlFglrkuKdPn9Km45c8j03ItxqMixry64GfJayFEB88CWqR46Kiongem4BBi/kULFX1/U/IYYnhQTw/NpOoqCgJaiHEB0+CWuSagqWqYljWPF+WnZQvSxVCiJwn46iFEEIILSZBLYQQQmgxCWohhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFsvXoL5w4QLDhg3DyckJMzMzjh07lqnN3bt3GTZsGPXq1cPGxoauXbsSEhKizk9MTGTu3LnY29tja2vL6NGjCQ8P13iNkJAQhgwZgrW1NQ4ODixZsoSUlBSNNufPn6dz585YWFjQsmVL9uzZk6mWHTt20KxZMywtLenWrRvXrl3LoXdCCCGEeLN8Deq4uDjMzMyYPXv2G+c/ePCAnj17Uq1aNbZv386BAwcYMWIEBQsWVNssXLiQkydP4u7uzvbt23n27BmjRo1S56empjJ06FCSk5Px8fFh8eLF7N27l1WrVqltHj58yNChQ7G3t2f//v3069ePGTNmcPr0abXN4cOHWbRoESNHjmTv3r2Ym5vj4uJCRERELrwzQgghRLoC+blwZ2dnnJ2d3zp/xYoVNG7cGFdXV3Va5cqV1f+/ePGC3bt3s2zZMhwcHID04G7bti2+vr7Y2Njw559/EhgYiKenJ6VKlaJ27dp88803LFu2jFGjRmFgYICPjw8VK1ZkypQpAFSvXp1Lly6xbds2GjVqBICnpydfffUVXbt2BWDu3LmcOnWK3bt3M2TIkBx/b4QQQgjQ4nPUaWlpnDp1iipVquDi4oKDgwPdunXTODzu5+dHcnIyjo6O6rTq1atTvnx5fH19AfD19aVWrVqUKlVKbePk5ERsbCyBgYFqm4ygf7VNxmskJSVx48YNjeXo6uri6OjIlStXcnrVhRBCCJXWBnVERARxcXF4eHjQqFEjtm7dSsuWLRk1ahR///03AOHh4ejr61O8eHGN55qYmBAWFqa2eTWkAfXx+9rExsaSkJDA8+fPSU1NxcTEJNNyXj8fLoQQQuSkfD30/S5paWkANG/enP79+wNQu3ZtLl++jI+PDw0aNMjH6oQQQoi8obV71MbGxhQoUIDq1atrTK9evbra67tUqVIkJycTExOj0SYiIgJTU1O1zet7vRmP39emaNGiGBoaYmxsjJ6eXqaOYxEREZn2xIUQQoicpLVBbWBggKWlJUFBQRrTg4ODqVChAgAWFhbo6+tz9uxZdf69e/cICQnBxsYGABsbG27fvq0RsmfOnKFo0aLUqFFDbXPu3DmN5Zw5c0Z9DQMDA+rWrauxnLS0NM6ePYutrW2OrbMQQgjxunw99P3y5UsePHigPn706BH+/v4YGRlRvnx5XFxcGDduHJ9++in29vacPn2akydP4uXlBUCxYsXo2rUrixcvxsjIiKJFi7JgwQJsbW3VkHVycqJGjRq4uroyadIkwsLCcHd3p1evXhgYGADw9ddfs2PHDpYuXUrXrl05d+4cR44cYePGjWptAwYMYPLkyVhYWGBlZcX3339PfHw8Xbp0ybs3TAghxEcnX4Paz8+Pvn37qo8XLVoEQOfOnVm8eDEtW7Zkzpw5bNq0iQULFlC1alVWrVpF/fr11edMmzYNXV1dxowZQ1JSEk5OThrjsvX09NiwYQNz5syhe/fuFCpUiM6dOzNmzBi1TaVKldi4cSOLFi3Cy8uLsmXLsmDBAnVoFkDbtm2JjIxk1apVhIWFUbt2bTZv3iyHvoUQQuQqHUVRlPwu4mORmpqqju/W09PL73JyTUBAAK279KbY194YljXP8+UnPA3ghU9vju7xxtw875cvhBDvk5080Npz1EIIIYSQoBZCCCG0mgS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSohRBCCC0mQS2EEEJoMQlqIYQQQotJUAshhBBaTIJaCCGE0GIS1EIIIYQWk6AWQgghtJgEtRBCCKHFJKiFEEIILSZBLYQQQmgxCWohhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFsvXoL5w4QLDhg3DyckJMzMzjh079ta2s2bNwszMjG3btmlMj4qKYsKECdjZ2VG/fn2mTZvGy5cvNdoEBATQs2dPLC0tcXZ2xsPDI9PrHzlyhDZt2mBpaUmHDh34/fffNeYrisLKlStxcnLCysqK/v37Exwc/I/XXQghhMiKfA3quLg4zMzMmD179jvb/fbbb1y9epXSpUtnmjdx4kQCAwPx9PRkw4YNXLx4kVmzZqnzY2NjcXFxoXz58uzZswdXV1fWrFnDzp071TaXL19mwoQJfPnll+zbt4/mzZszcuRIbt++rbbx8PBg+/btzJkzh127dlGoUCFcXFxITEzMgXdCCCGEeLN8DWpnZ2fGjRtHy5Yt39omNDSU+fPns2zZMvT19TXm3b17l9OnT7NgwQKsra2pX78+M2bM4JdffiE0NBSAAwcOkJyczMKFC6lZsybt2rWjT58+eHp6qq/j5eVFo0aNGDRoENWrV2fs2LHUqVMHb29vIH1v2svLi+HDh9OiRQvMzc1ZunQpz549e+dRACGEEOLf0upz1GlpaUyaNAkXFxdq1qyZaf6VK1coXrw4lpaW6jRHR0d0dXW5du0aAL6+vtSvXx8DAwO1jZOTE0FBQURHR6ttHBwcNF7byckJX19fAB49ekRYWBiOjo7q/GLFimFtbc2VK1dybH2FEEKI12l1UHt4eFCgQAH69u37xvnh4eGULFlSY1qBAgUwMjIiLCxMbVOqVCmNNhmPw8PD39rGxMREnZ/xWiYmJm9tI4QQQuSGAvldwNv4+fnh5eXFnj170NHRye9yhBBCiHyhtXvUFy9eJCIigqZNm1KnTh3q1KnD48ePWbJkCc2aNQPS94wjIyM1npeSkkJ0dDSmpqZqm9f3ejMeZ+xFv6lNRESEOj/jtSIiIt7aRgghhMgNWhvUnTp14sCBA+zbt0/9V7p0aVxcXNi8eTMAtra2xMTE4Ofnpz7v3LlzpKWlYWVlBYCNjQ0XL14kOTlZbXPmzBmqVq2KkZGR2ubcuXMayz9z5gw2NjYAVKxYEVNTU86ePavOj42N5erVq9ja2ubK+gshhBCQz0H98uVL/P398ff3B9I7bfn7+xMSEoKxsTG1atXS+Kevr0+pUqWoVq0aANWrV6dRo0bMnDmTa9eucenSJebPn0+7du0oU6YMAB06dEBfX5/p06dz584dDh8+jJeXFwMGDFDr6Nu3L6dPn2br1q3cvXuX1atX4+fnR+/evQHQ0dGhb9++rF+/nuPHj3Pr1i1cXV0pXbo0LVq0yON3TQghxMckX89R+/n5aXQUW7RoEQCdO3dm8eLFWXqNZcuWMX/+fPr164euri6tWrVixowZ6vxixYqxZcsW5s2bR5cuXTA2NmbEiBF0795dbWNnZ8eyZctwd3fHzc2NKlWqsHbtWmrVqqW2GTx4MPHx8cyaNYuYmBjq1avH5s2bKViw4L99G4QQQoi30lEURcnvIj4Wqamp+Pr6YmNjg56eXn6Xk2sCAgJo3aU3xb72xrCseZ4vP+FpAC98enN0jzfm5nm/fCGEeJ/s5IHWnqMWQgghhAS1EEIIodUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSohRBCCC0mQS2EEEJoMQlqIYQQQotJUAshhBBaTIJaCCGE0GIS1EIIIYQWk6AWQgghtJgEtRBCCKHFJKiFEEIILSZBLYQQQmgxCWohhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbRYvgb1hQsXGDZsGE5OTpiZmXHs2DF1XnJyMt999x0dOnTAxsYGJycnXF1dCQ0N1XiNqKgoJkyYgJ2dHfXr12fatGm8fPlSo01AQAA9e/bE0tISZ2dnPDw8MtVy5MgR2rRpg6WlJR06dOD333/XmK8oCitXrsTJyQkrKyv69+9PcHBwzr0ZQgghxBvka1DHxcVhZmbG7NmzM81LSEjg5s2bDB8+nD179rBmzRqCgoIYPny4RruJEycSGBiIp6cnGzZs4OLFi8yaNUudHxsbi4uLC+XLl2fPnj24urqyZs0adu7cqba5fPkyEyZM4Msvv2Tfvn00b96ckSNHcvv2bbWNh4cH27dvZ86cOezatYtChQrh4uJCYmJiLrwzQgghRLoC+blwZ2dnnJ2d3zivWLFieHp6akybOXMm3bp1IyQkhPLly3P37l1Onz7Nzz//jKWlJQAzZsxgyJAhuLq6UqZMGQ4cOEBycjILFy7EwMCAmjVr4u/vj6enJ927dwfAy8uLRo0aMWjQIADGjh3LmTNn8Pb2Zt68eSiKgpeXF8OHD6dFixYALF26FEdHR44dO0a7du1y6y0SQgjxkfugzlHHxsaio6ND8eLFAbhy5QrFixdXQxrA0dERXV1drl27BoCvry/169fHwMBAbePk5ERQUBDR0dFqGwcHB41lOTk54evrC8CjR48ICwvD0dFRnV+sWDGsra25cuVKrqyrEEIIAR9QUCcmJrJs2TLatWtH0aJFAQgPD6dkyZIa7QoUKICRkRFhYWFqm1KlSmm0yXgcHh7+1jYmJibq/IzXMjExeWsbIYQQIjd8EEGdnJzMN998g6IozJ07N7/LEUIIIfKM1gd1cnIyY8eOJSQkhK1bt6p705C+ZxwZGanRPiUlhejoaExNTdU2r+/1ZjzO2It+U5uIiAh1fsZrRUREvLWNEEIIkRu0OqgzQvr+/fts27YNY2Njjfm2trbExMTg5+enTjt37hxpaWlYWVkBYGNjw8WLF0lOTlbbnDlzhqpVq2JkZKS2OXfunMZrnzlzBhsbGwAqVqyIqakpZ8+eVefHxsZy9epVbG1tc3SdhRBCiFfla1C/fPkSf39//P39gfROW/7+/oSEhJCcnMyYMWPw8/Nj2bJlpKamEhYWRlhYGElJSQBUr16dRo0aMXPmTK5du8alS5eYP38+7dq1o0yZMgB06NABfX19pk+fzp07dzh8+DBeXl4MGDBAraNv376cPn2arVu3cvfuXVavXo2fnx+9e/cGQEdHh759+7J+/XqOHz/OrVu3cHV1pXTp0movcCGEECI35OvwLD8/P/r27as+XrRoEQCdO3dm1KhRnDhxAoBOnTppPM/Lywt7e3sAli1bxvz58+nXrx+6urq0atWKGTNmqG2LFSvGli1bmDdvHl26dMHY2JgRI0aoQ7MA7OzsWLZsGe7u7ri5uVGlShXWrl1LrVq11DaDBw8mPj6eWbNmERMTQ7169di8eTMFCxbM+TdGCCGE+P90FEVR8ruIj0Vqaiq+vr7Y2Nigp6eX3+XkmoCAAFp36U2xr70xLGue58tPeBrAC5/eHN3jjbl53i9fCCHeJzt5oNXnqIUQQoiPnQS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSohRBCCC0mQS2EEEJoMQlqIYQQQotJUAshhBBaTIJaCCGE0GIS1EIIIYQWk6AWQgghtJgEtRBCCKHFciSoo6Ojc+JlhBBCCPGabAf1vn37mDp1Krdu3SI8PJwOHTrw2Wef0bRpU27fvp0bNQohhBAfrWwH9c6dOzl48CDlypXDx8eHO3fuoCgKT548YeXKlblRoxBCCPHRynZQBwcHU65cOYoXL86VK1cwNjZm586dFC1alKtXr+ZGjUIIIcRHK9tBHRsbS7FixQAICgqibt26WFtbU7lyZTlXLYQQQuSwbAe1iYkJd+/eZePGjTx58oRatWoB6R3KjIyMcrxAIYQQ4mOW7aB2dnYmMTERd3d3AJo1a0ZUVBShoaHUqFEjp+sTQgghPmoFsvuEyZMnY2hoyP3792nWrBn169fn2rVrfP755zRp0iQXShRCCCE+XtkO6sKFCzN16lSNaVZWVnz33Xc5VpQQQggh0mU7qAFiYmK4du0a4eHhmeZ98cUX/7YmIYQQQvx/2Q7qU6dOMXHiRF6+fJlpno6OjgS1EEIIkYOyHdRLliwhNjY2N2oRQgghxGuyHdQhISEUKlSI5cuXU6NGDfT09HKjLiGEEELwD4LawsKCiIgImjVrlhv1CCGEEOIV2R5HPXDgQB49esTSpUsJCAggJCRE458QQgghck62g3rkyJGkpqbi6elJ586dad68ufqvRYsW2XqtCxcuMGzYMJycnDAzM+PYsWMa8xVFYeXKlTg5OWFlZUX//v0JDg7WaBMVFcWECROws7Ojfv36TJs2LVNHt4CAAHr27ImlpSXOzs54eHhkquXIkSO0adMGS0tLOnTowO+//57tWoQQQoic9o/uR60oylv/ZUdcXBxmZmbMnj37jfM9PDzYvn07c+bMYdeuXRQqVAgXFxcSExPVNhMnTiQwMBBPT082bNjAxYsXmTVrljo/NjYWFxcXypcvz549e3B1dWXNmjXs3LlTbXP58mUmTJjAl19+yb59+2jevDkjR47UuG1nVmoRQgghclq2z1F7eXnl2MKdnZ1xdnZ+4zxFUfDy8mL48OHqnvrSpUtxdHTk2LFjtGvXjrt373L69Gl+/vlnLC0tAZgxYwZDhgzB1dWVMmXKcODAAZKTk1m4cCEGBgbUrFkTf39/PD096d69u7pOjRo1YtCgQQCMHTuWM2fO4O3tzbx587JUixBCCJEbsh3UDRo0yI06Mnn06BFhYWE4Ojqq04oVK4a1tTVXrlyhXbt2XLlyheLFi6shDeDo6Iiuri7Xrl2jZcuW+Pr6Ur9+fQwMDNQ2Tk5OeHh4qDcS8fX1pX///hrLd3JyUg/FZ6UWIYQQIjf8oyuT3bt3j40bN+Lr60vVqlUZNmwYf/75J61atVLvpvVvhYWFAel363qViYmJekW08PBwSpYsqTG/QIECGBkZqc8PDw+nYsWKGm1KlSqlzjMyMiI8PFyd9qblZKUWIYQQIjdkO6gzOmbFx8ejKArGxsYULFiQNWvWEBkZqXF+WAghhBD/TrY7ky1btoy4uDjq1q2rTqtduzZGRkacP38+xwozNTUFICIiQmN6RESEuvdbqlQpIiMjNeanpKQQHR2tPr9UqVKZ9nozHr/6Oq+3eXU5WalFCCGEyA3ZDurLly9TpkwZjV7TAOXKlePJkyc5VljFihUxNTXl7Nmz6rTY2FiuXr2Kra0tALa2tsTExODn56e2OXfuHGlpaVhZWQFgY2PDxYsXSU5OVtucOXOGqlWrYmRkpLY5d+6cxvLPnDmDjY1NlmsRQgghckO2gzotLY3ChQtnunRoZGRktodnvXz5En9/f/z9/YH0Tlv+/v6EhISgo6ND3759Wb9+PcePH+fWrVu4urpSunRpted19erVadSoETNnzuTatWtcunSJ+fPn065dO8qUKQNAhw4d0NfXZ/r06dy5c4fDhw/j5eXFgAED1Dr69u3L6dOn2bp1K3fv3mX16tX4+fnRu3dvgCzVIoQQQuSGbJ+jrl69Ojdv3mTdunVA+p7lkiVLePbsmboXm1V+fn707dtXfbxo0SIAOnfuzOLFixk8eDDx8fHMmjWLmJgY6tWrx+bNmylYsKD6nGXLljF//nz69euHrq4urVq1YsaMGer8YsWKsWXLFubNm0eXLl0wNjZmxIgR6tAsADs7O5YtW4a7uztubm5UqVKFtWvXanSMy0otQgghRE7TUbK5G7x//34mT56Mjo5OpnmLFy+mU6dOOVbcf01qaiq+vr7Y2Nj8p29mEhAQQOsuvSn2tTeGZc3zfPkJTwN44dObo3u8MTfP++ULIcT7ZCcPsn3ou1OnTkyYMAFDQ0P1amQFCxZk3LhxEtJCCCFEDsv2oe/Q0FAGDx5Mnz59uHPnDgA1a9bE0NCQ//3vf7Rq1SrHixRCCCE+Vtneo+7bty/Pnj3D0NAQS0tLLC0tMTQ05KeffmLcuHG5UaMQQgjx0cp2UN+/f18N6wweHh7MnDmTtLS0HC1OCCGE+NhlO6jt7OwIDg6mX79+PHv2jKVLl+Lm5gZAt27dcrxAIYQQ4mOW7XPUW7duZcSIEZw5c4bPP/+cuLg4FEVh1KhRjBo1KjdqFEIIIT5a2d6jNjQ0ZMOGDTRv3pyXL1+ip6fHggULJKSFEEKIXJClPermzZtnmpaamoqOjg4FChRg/fr1rF+/Hh0dHfXWkEIIIYT497IU1I8fP37rvISEBHX+my6CIoQQQoh/LktBLYe1hRBCiPwhQS2EEEJosWz3+gZ4/vw5O3bsUG8vaWFhQa9evTA2Ns7R4oQQQoiPXbaD+smTJ3z99dcaFzz5/fff+fnnn/Hx8aFs2bI5WqAQQgjxMcv28Cw3NzdCQ0PR0dGhWrVqVKtWDR0dHUJDQ1mxYkVu1CiEEEJ8tLK9R33mzBkMDQ354YcfqFOnDgA3btygZ8+e/PnnnzleoBBCCPExy/YedXR0NJUqVVJDGqBu3bpUqlSJ6OjoHC1OCCGE+NhlO6hLlSpFUFAQJ06cUKcdP36c4OBgTE1Nc7Q4IYQQ4mOX7UPfTZs25ccff2TkyJEYGhoC6Rc9AWjWrFnOVieEEEJ85LK9Rz127Fhq1qyJoijEx8cTHx+PoijUqFGDb775JjdqFEIIIT5a2d6jNjIyYvfu3Rw6dIjr168DYGlpSfv27TEwMMjxAoUQQoiPWbaDet++fRgbG9OlSxe6dOmiTn/06BEJCQnUqFEjRwsUQgghPmbZPvQ9ZcoU1q9fn2n6hAkT6NixY44UJYQQQoh02Q7qt4mKikJRlJx6OSGEEEKQjUPfr96T+ubNmxqPExISiIyMpESJEjlanBBCCPGxy3JQv3rP6aSkpDfeo7ply5Y5V5kQQgghsh7UGbe6XLNmDWXLluXLL79U5xkaGlKtWjWaNm2a8xUKIYQQH7FsB/X58+epWbOm3KNaCCGEyAPZHp61ffv23KhDCCGEEG+QY72+hRBCCJHzJKiFEEIILSZBLYQQQmixLAX1vn37+P333wG4cOEC/v7+uVqUEEIIIdJlKahfvWxonz59mDt3bq4WJYQQQoh0WQrqAgUK8PTpU4KDgwFISkriyZMnhISEZPqXk1JTU3F3d6dZs2ZYWVnRokUL1q5dq3GpUkVRWLlyJU5OTlhZWdG/f3+1zgxRUVFMmDABOzs76tevz7Rp03j58qVGm4CAAHr27ImlpSXOzs54eHhkqufIkSO0adMGS0tLOnTooB5lEEIIIXJLloZnVahQgQcPHvD555+jo6ODv78/zZo1y9ROR0eHmzdv5lhxHh4e/PjjjyxZsoQaNWrg5+fH1KlTKVasGH379lXbbN++ncWLF1OxYkVWrlyJi4sLhw8fpmDBggBMnDiRsLAwPD09SU5OZtq0acyaNYvly5cDEBsbi4uLCw4ODsydO5fbt28zbdo0ihcvTvfu3QG4fPkyEyZMYPz48TRt2pSDBw8ycuRI9uzZQ61atXJsnYUQQohXZWmPevjw4ejp6al7soqivPVfTrpy5QrNmzenSZMmVKxYkTZt2uDk5MS1a9fUOry8vBg+fDgtWrTA3NycpUuX8uzZM44dOwbA3bt3OX36NAsWLMDa2pr69eszY8YMfvnlF0JDQwE4cOAAycnJLFy4kJo1a9KuXTv69OmDp6enWouXlxeNGjVi0KBBVK9enbFjx1KnTh28vb1zdJ2FEEKIV2UpqL/44gv++OMPvL29URSFGjVq4OXllenf999/n6PF2dracu7cOYKCgoD0w9OXLl2icePGQPo9sMPCwnB0dFSfU6xYMaytrbly5QqQHvbFixfH0tJSbePo6Iiurq4a+L6+vtSvXx8DAwO1jZOTE0FBQURHR6ttHBwcNOpzcnLC19c3R9dZCCGEeFWWr0xWsmRJSpYsyahRoyhTpgwNGjTIzboAGDJkCLGxsXz++efo6emRmprKuHHj1Pteh4WFAWBiYqLxPBMTE8LDwwEIDw+nZMmSGvMLFCiAkZGR+vzw8HAqVqyo0aZUqVLqPCMjI8LDw9Vpb1qOEEIIkRuyfQnRUaNGkZSUxN69e/Hz8wPAwsKCdu3aaeyR5oQjR45w8OBBli9fTo0aNfD392fRokWULl2azp075+iyhBBCCG2U7aCOjo6mT58+3LlzR2P6tm3b2L59O8WLF8+x4pYuXcqQIUNo164dAGZmZoSEhLBx40Y6d+6MqakpABEREZQuXVp9XkREBObm5kD6nnFkZKTG66akpBAdHa0+v1SpUpn2jDMeZ+xFv6lNREREpr1sIYQQIidl+8pk7u7u3L59G0VRMDQ0xNDQEEVRuH37Nu7u7jlaXEJCAjo6OhrTXu3UVrFiRUxNTTl79qw6PzY2lqtXr2Jrawukn+eOiYlR9/4Bzp07R1paGlZWVgDY2Nhw8eJFkpOT1TZnzpyhatWqGBkZqW3OnTunUcuZM2ewsbHJuRUWQgghXpPtoD5x4gQFChRgzZo1XLlyhStXrrBmzRr09PQ4ceJEjhbXtGlTNmzYwKlTp3j06BG//fYbnp6etGjRAkgfDta3b1/Wr1/P8ePHuXXrFq6urpQuXVptU716dRo1asTMmTO5du0aly5dYv78+bRr144yZcoA0KFDB/T19Zk+fTp37tzh8OHDeHl5MWDAALWWvn37cvr0abZu3crdu3dZvXo1fn5+9O7dO0fXWQghhHhVtg99R0REULVqVTUIAVq0aEHVqlXV3tk5ZcaMGaxcuZK5c+eqh7e7d+/OyJEj1TaDBw8mPj6eWbNmERMTQ7169di8ebM6hhpg2bJlzJ8/n379+qGrq0urVq2YMWOGOr9YsWJs2bKFefPm0aVLF4yNjRkxYoQ6hhrAzs6OZcuW4e7ujpubG1WqVGHt2rUyhloIIUSu0lGyOfjZycmJFy9esHPnTvU8sL+/P927d6d48eL8+eefuVLof0Fqaiq+vr7Y2Nigp6eX3+XkmoCAAFp36U2xr70xLGue58tPeBrAC5/eHN3jrX5GhRBCm2QnD7K9R+3o6MiBAwfo2rUrVatWBSAoKIi0tDScnJz+WcVCCCGEeKNsn6MeN24cpqampKamEhgYSGBgIKmpqZQqVYqxY8fmQolCCCHExyvbe9TlypVj//797Nixg+vXrwNgaWlJr169Ml1YRAghhBD/TraDGtKvUjZ69OicrkUIIYQQr8n2oW8hhBBC5B0JaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFst2UPft25f58+fnRi1CCCGEeE2Wg/qnn34iOjqav//+mxs3bqjTa9euzddff50rxQkhhBAfuywH9cyZM2nYsCEAT58+Zd++fdy9e5dsXipcCCGEENmQ5aA+efIkEyZMANKDesqUKbRv3x4dHR2Cg4PZsGEDAQEBuVaoEEII8THKclAbGhqq92e2sbHh6NGjLF68GEVRSExMZP369XTu3DnXChVCCCE+RlkOaicnJ/r37w9AfHw8pqamdOrUCQAzMzPOnTvH2rVrc6VIIYQQ4mOV5aCeOHEiCQkJANy+fZv69evTrl07AJ4/f87jx49p1qxZ7lQphBBCfKSyHNQDBgzAx8cHgE8++YSxY8fyySefAPDgwQM6dOhA8+bNc6dKIYQQ4iP1j+6eVaJECYYMGQKAubk55ubmDB48mN9//z1HixNCCCE+dtkOai8vL4oWLaoxrWDBgrRt25a2bdvmWGFCCCGE+AdB3aBBA43HMiRLCCGEyD1yrW8hhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxbQ+qENDQ5k4cSL29vZYWVnRoUMHrl+/rs5XFIWVK1fi5OSElZUV/fv3Jzg4WOM1oqKimDBhAnZ2dtSvX59p06bx8uVLjTYBAQH07NkTS0tLnJ2d8fDwyFTLkSNHaNOmDZaWlnTo0IHff/89V9ZZCCGEyKDVQR0dHU2PHj3Q19fHw8ODX375hcmTJ2NkZKS28fDwYPv27cyZM4ddu3ZRqFAhXFxcSExMVNtMnDiRwMBAPD092bBhAxcvXmTWrFnq/NjYWFxcXChfvjx79uzB1dWVNWvWsHPnTrXN5cuXmTBhAl9++SX79u2jefPmjBw5ktu3b+fNmyGEEOKjpNVB7eHhQdmyZVm0aBFWVlZUqlQJJycnKleuDKTvTXt5eTF8+HBatGiBubk5S5cu5dmzZxw7dgyAu3fvcvr0aRYsWIC1tTX169dnxowZ/PLLL4SGhgJw4MABkpOTWbhwITVr1qRdu3b06dMHT09PtRYvLy8aNWrEoEGDqF69OmPHjqVOnTp4e3vn/RsjhBDio6HVQX3ixAksLCwYM2YMDg4OfPHFF+zatUud/+jRI8LCwnB0dFSnFStWDGtra65cuQLAlStXKF68OJaWlmobR0dHdHV1uXbtGgC+vr7Ur18fAwMDtY2TkxNBQUFER0erbRwcHDTqc3JywtfXN8fXWwghhMig1UH98OFDfvzxR6pUqcKWLVvo0aMHCxYsYO/evQCEhYUBYGJiovE8ExMTwsPDAQgPD6dkyZIa8wsUKICRkZH6/PDwcEqVKqXRJuPxq6/zeptXlyOEEELkhgL5XcC7KIqChYUF48ePB6BOnTrcuXMHHx8fOnfunM/VCSGEELlPq/eoTU1NqV69usa0atWqERISos4HiIiI0GgTERGh7v2WKlWKyMhIjfkpKSlER0erzy9VqlSmPeOMx6++zuttXl2OEEIIkRu0Oqjt7OwICgrSmBYcHEyFChUAqFixIqamppw9e1adHxsby9WrV7G1tQXA1taWmJgY/Pz81Dbnzp0jLS0NKysrAGxsbLh48SLJyclqmzNnzlC1alW1h7mNjQ3nzp3TqOXMmTPY2Njk3AoLIYQQr9HqoO7Xrx9Xr15lw4YN3L9/n4MHD7Jr1y569uwJgI6ODn379mX9+vUcP36cW7du4erqSunSpWnRogUA1atXp1GjRsycOZNr165x6dIl5s+fT7t27ShTpgwAHTp0QF9fn+nTp3Pnzh0OHz6Ml5cXAwYMUGvp27cvp0+fZuvWrdy9e5fVq1fj5+dH79698/6NEUII8dHQ6nPUVlZWrFmzBjc3N9auXUvFihWZNm0aHTt2VNsMHjyY+Ph4Zs2aRUxMDPXq1WPz5s0ULFhQbbNs2TLmz59Pv3790NXVpVWrVsyYMUOdX6xYMbZs2cK8efPo0qULxsbGjBgxgu7du6tt7OzsWLZsGe7u7ri5uVGlShXWrl1LrVq18ubNEEII8VHSURRFye8iPhapqan4+vpiY2ODnp5efpeTawICAmjdpTfFvvbGsKx5ni8/4WkAL3x6c3SPN+bmeb98IYR4n+zkgVYf+hZCCCE+dhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSohRBCCC0mQS2EEEJoMQlqIYQQQotJUAshhBBaTIJaCCGE0GIS1EIIIYQWk6AWQgghtJgEtRBCCKHFJKiFEEIILSZBLYQQQmgxCWohhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiH1RQb9q0CTMzM7799lt1WmJiInPnzsXe3h5bW1tGjx5NeHi4xvNCQkIYMmQI1tbWODg4sGTJElJSUjTanD9/ns6dO2NhYUHLli3Zs2dPpuXv2LGDZs2aYWlpSbdu3bh27VrurKgQQgjx/30wQX3t2jV8fHwwMzPTmL5w4UJOnjyJu7s727dv59mzZ4waNUqdn5qaytChQ0lOTsbHx4fFixezd+9eVq1apbZ5+PAhQ4cOxd7env3799OvXz9mzJjB6dOn1TaHDx9m0aJFjBw5kr1792Jubo6LiwsRERG5v/JCCCE+Wh9EUL98+ZJJkyaxYMECjIyM1OkvXrxg9+7dTJkyBQcHBywsLFi4cCFXrlzB19cXgD///JPAwEC+++47ateujbOzM9988w07duwgKSkJAB8fHypWrMiUKVOoXr06vXv3pnXr1mzbtk1dlqenJ1999RVdu3alRo0azJ07F0NDQ3bv3p2Xb4UQQoiPzAcR1PPmzcPZ2RlHR0eN6X5+fiQnJ2tMr169OuXLl1eD2tfXl1q1alGqVCm1jZOTE7GxsQQGBqptHBwcNF7byclJfY2kpCRu3LihsRxdXV0cHR25cuVKTq6qEEIIoaFAfhfwPr/88gs3b97k559/zjQvPDwcfX19ihcvrjHdxMSEsLAwtc2rIQ2oj9/XJjY2loSEBKKjo0lNTcXExCTTcu7du/fvVlAIIYR4B60O6idPnvDtt9+ydetWChYsmN/lCCGEEHlOq4P6xo0bRERE0KVLF3VaamoqFy5cYMeOHWzZsoXk5GRiYmI09qojIiIwNTUF0veMX++dndEr/NU2r/cUDw8Pp2jRohgaGqKrq4uenl6mjmMRERGZ9sSFEEKInKTV56g/++wzDh48yL59+9R/FhYWdOjQQf2/vr4+Z8+eVZ9z7949QkJCsLGxAcDGxobbt29rhOyZM2coWrQoNWrUUNucO3dOY9lnzpxRX8PAwIC6detqLCctLY2zZ89ia2ubS2svhBBCaPkeddGiRalVq5bGtMKFC1OiRAl1eteuXVm8eDFGRkYULVqUBQsWYGtrq4ask5MTNWrUwNXVlUmTJhEWFoa7uzu9evXCwMAAgK+//podO3awdOlSunbtyrlz5zhy5AgbN25UlztgwAAmT56MhYUFVlZWfP/998THx2vs7QshhBA5TauDOiumTZuGrq4uY8aMISkpCScnJ2bPnq3O19PTY8OGDcyZM4fu3btTqFAhOnfuzJgxY9Q2lSpVYuPGjSxatAgvLy/Kli3LggULaNSokdqmbdu2REZGsmrVKsLCwqhduzabN2+WQ99CCCFylY6iKEp+F/GxSE1NxdfXFxsbG/T09PK7nFwTEBBA6y69Kfa1N4ZlzfN8+QlPA3jh05uje7wxN8/75QshxPtkJw+0+hy1EEII8bGToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSohRBCCC0mQS2EEEJoMQlqIYQQQotJUAshhBBaTIJaCCGE0GIS1EIIIYQWk6AWQgghtJgEtRBCCKHFJKiFEEIILSZBLYQQQmgxCWohhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZCCCG0mAS1EEIIocUkqIUQQggtJkEthBBCaDEJaiGEEEKLSVALIYQQWkyCWgghhNBiEtRCCCGEFtP6oN64cSNdu3bF1tYWBwcHRowYwb179zTaJCYmMnfuXOzt7bG1tWX06NGEh4drtAkJCWHIkCFYW1vj4ODAkiVLSElJ0Whz/vx5OnfujIWFBS1btmTPnj2Z6tmxYwfNmjXD0tKSbt26ce3atZxfaSGEEOL/0/qg/vvvv+nVqxe7du3C09OTlJQUXFxciIuLU9ssXLiQkydP4u7uzvbt23n27BmjRo1S56empjJ06FCSk5Px8fFh8eLF7N27l1WrVqltHj58yNChQ7G3t2f//v3069ePGTNmcPr0abXN4cOHWbRoESNHjmTv3r2Ym5vj4uJCRERE3rwZQgghPjpaH9RbtmyhS5cu1KxZE3NzcxYvXkxISAg3btwA4MWLF+zevZspU6bg4OCAhYUFCxcu5MqVK/j6+gLw559/EhgYyHfffUft2rVxdnbmm2++YceOHSQlJQHg4+NDxYoVmTJlCtWrV6d37960bt2abdu2qbV4enry1Vdf0bVrV2rUqMHcuXMxNDRk9+7def22CCGE+EhofVC/7sWLFwAYGRkB4OfnR3JyMo6Ojmqb6tWrU758eTWofX19qVWrFqVKlVLbODk5ERsbS2BgoNrGwcFBY1lOTk7qayQlJXHjxg2N5ejq6uLo6MiVK1dyfD2FEEII+MCCOi0tjYULF2JnZ0etWrUACA8PR19fn+LFi2u0NTExISwsTG3zakgD6uP3tYmNjSUhIYHnz5+TmpqKiYlJpuW8fj5cCCGEyCkF8ruA7Jg7dy537tzhhx9+yO9ShBBCiDzxwexRz5s3j1OnTvH9999TtmxZdXqpUqVITk4mJiZGo31ERASmpqZqm9f3ejMev69N0aJFMTQ0xNjYGD09vUwdxyIiIjLtiQshhBA5ReuDWlEU5s2bx2+//cb3339PpUqVNOZbWFigr6/P2bNn1Wn37t0jJCQEGxsbAGxsbLh9+7ZGyJ45c4aiRYtSo0YNtc25c+c0XvvMmTPqaxgYGFC3bl2N5aSlpXH27FlsbW1zcpWFEEIIldYH9dy5czlw4ADLly+nSJEihIWFERYWRkJCAgDFihWja9euLF68mHPnzuHn58e0adOwtbVVQ9bJyYkaNWrg6upKQEAAp0+fxt3dnV69emFgYADA119/zcOHD1m6dCl3795lx44dHDlyhP79+6u1DBgwgF27drF3717u3r3LnDlziI+Pp0uXLnn9tgghhPhIaP056h9//BGAPn36aExftGiRGpDTpk1DV1eXMWPGkJSUhJOTE7Nnz1bb6unpsWHDBubMmUP37t0pVKgQnTt3ZsyYMWqbSpUqsXHjRhYtWoSXlxdly5ZlwYIFNGrUSG3Ttm1bIiMjWbVqFWFhYdSuXZvNmzfLoW8hhBC5RkdRFCW/i/hYpKam4uvri42NDXp6evldTq4JCAigdZfeFPvaG8Oy5nm+/ISnAbzw6c3RPd6Ym+f98oUQ4n2ykwdaf+hbCCGE+JhJUAshhBBaTIJaCCGE0GIS1EIIIYQWk6AWQgghtJgEtRBCCKHFJKiFEEIILSZBLYQQQmgxCWohhBBCi0lQCyGEEFpMgloIIYTQYhLUQgghhBaToBZC/CedP38eMzOzTP+aNWsGwNixY3FyclKnv8nDhw+pV68eZmZmjBs3Tp2enJzMokWLcHBwwNLSkj59+nDnzp08WS/x8ZGgFkKLKYrCli1baNWqFRYWFjg6OrJs2TIAkpKSWL58OU2aNMHCwoLGjRvj5eWlPvf48eO0b98eCwsLmjVrho+PjzrvYwiaGjVq4Obmpv5r27YtAFZWVgDo6OjQtWvXtz4/NTWVSZMmkZaWlmnexo0b2bZtG/b29kyYMIFr164xbNgwkpOTc2dlxEdNgvoD97Yf8piYGLp27YqdnZ36Q7169Woy7mr6008/0blzZ+rVq4ednR29e/fm+vXr6uv+/vvvdOnSBQsLC8zMzFi9enV+reJHzd3dnaVLl2JkZMTMmTMZMmQI+vr6AEydOpVNmzZRvXp1Zs+eTa9evdS/7/379xkzZgxxcXFMnz6dkiVLMnv2bM6cOQN8HEFjYmJCu3btaNeuHW3btsXf3x8AFxcXAFasWMGIESPe+vy1a9fy4MEDhg8fnmmet7c3Ojo6zJ8/n/79+9OiRQsePXrEqVOncmVdxMetQH4XIP4dd3d3NmzYgJWVFS4uLsTHxxMdHQ1AgwYN+Prrr0lKSmL9+vWsWbMGS0tLmjRpwtWrV6levTpff/01fn5+7Nq1i6FDh3L69Gn09PSIj4+nTp06FC1alPPnz+fzWn6c4uPj2bZtG4ULF2bLli3o6+tTqFAhIP2Q7KFDh6hYsSLr168nLS0NQ0ND9bk+Pj6kpKQwYMAAevToQaVKlXBxcWH79u04OjpqBE2xYsW4fv06hw4d4tSpU7Rs2TK/VjnXnDx5kqCgIBo0aIClpeV721+6dImNGzeybt06IiIiNObFxMTw/PlzihcvTrFixQAoX748AEFBQTlfvPjoSVB/wN71Qw4wefJkIiMjef78OT/99BNhYWHo6OgAMGvWLAwMDADo3r07R48eJSIigmfPnlGuXDnatGlDmzZtWLZsmQR1Prlz5w4JCQmUKFGC9u3bExoaStmyZZk+fTqpqakApKSk0KhRI6KioqhatSrz58/n008/5f79+wCUK1cO+L8gCQ4O/iiDxtPTE/i/ven3mTRpEs2bN6dKlSrcvn0bgLi4OJ48eUKRIkUytc84kiFEbpBD3x+wjB9yAwMD2rdvj42NDc7Ozvzvf/8D4OXLlzg4OKiH/VxcXGjcuDGAGtIAFy9eJDo6mmrVqlGmTJl8WReRmZ6eHgBRUVF069aNJUuWEBkZyYQJE9DVTf/qhoaGMmbMGKZNm0ZQUBDffPPNG0PjfUHyXw4aPz8//v77b2rUqIGzs3OWnvP48WOOHj1Kq1at1D4Bp06dYtiwYRQvXhxjY2NevHhBTEwMAE+ePAGgSpUqubIO4uMmQf0Be9cP+fPnzzE0NMTT05MlS5bwySef8MMPP3DlyhWN1zh//jzDhw/H1NSU1atXqwEg8l+lSpXUv8eQIUP44osvqFatGklJSZiYmADp52F79epFv379KFasGBEREcTExPDJJ58AEBISAvxfkHzyySe5EjTz589Xe0/fvXsX4I09rjPOE7+vj8Tly5fp2bMn9erVw8bGhk6dOvHrr7/+o9q2bt0KwIABA9QjSgCHDx9mz5496uOffvpJPce8cuVK9V+vXr0AsLOzY/LkyQD07NkTRVGYNWsW27Zt49ixY1SoUIEmTZr8oxqFeBc59P0By/ghT0tLY8iQIRQsWBBPT08CAgJ48uQJxsbGODo6AhAWFsayZcv45ZdfsLOzA+CXX35h8uTJlCtXjs2bN6s/7kI7FC9enA4dOrB//36+++47KlSoQGBgIKVLl8bS0pL69etz8eJF1qxZQ2pqKi9evKBu3boYGRnRvXt3vv/+e7Zt24aBgQE///wzAH369AHSg2bt2rXMmjULGxubfxU0p06dwsfHh4IFC5KYmKgx79NPP6VHjx7q4woVKgC8t4/EhAkTCAkJYdiwYRQuXBh3d3cmTJhA48aNKVy4cJZrCwkJ4ejRo5iamtKxY0eNecuWLePx48fq4xkzZtCgQQOaNGlCmzZt1OlxcXEAlC1bVv0+DRs2jJiYGA4dOsTx48extrZm5syZGkeqhMgpEtQfsHf9kF+5coWdO3diYWFBfHw83t7eAJibmwPpew8zZ86kYMGC9OnTBz8/P/z8/Pjss88wMTEhODiYCxcucOvWLQBu3LjBTz/9hLOzM6VLl863dc5pffr0ISAggPj4eEqWLEnLli2ZPHmy+oMbExNDx44defLkCdbW1uzatQtI3xtzc3MjNDQUfX19atasybhx4/jss88AOHHiBGvWrCEoKAgdHR1q1qzJ+PHjsbe3z1Z9M2fOREdHh3379qEoCvb29ri6ulKwYEHc3NyYO3cuW7ZswcDAgJYtWzJ16lQgfc941apVrFixggULFlC6dGlmzZpFw4YNgZwLmvDwcKZNm8bQoUPZt2+fRvABVKxYEWdnZ4oWLaox/X19JDKGRNnb21O0aFHWrl1LoUKF1KNIWVW+fHlu3LjxxnknTpzI0mt06dKFLl26aEwzMDBgxowZzJgxI1v1vO5tn79Zs2axd+/eTO1HjRrF6NGjSU5OZtmyZRw4cIDY2FhsbGyYNWsWNWvW1Gg/f/589bt/+PBhqlev/q/qFflDgvoD97Yf8qdPn7Jjxw727duHrq4u5cuXZ9KkSXTr1g1I79WqKAoJCQl8++236ut5eXlhYmLC5cuXNX6ETp48ycmTJ/Hy8vpPBXXt2rXp0KEDOjo6bN26FW9vb6pVq6Ye7pw5c6bai/5VhoaGfPXVV5QuXRp/f3+2bdvGuHHjOHv2LAkJCXzzzTekpKQwadIkwsLC2Lp1KxMmTODPP//MVn3FihVjyZIlb5xXpkwZ1q1b99bntmjRghYtWrxxXk4EjaIoTJkyhcqVKzNy5Ej27duXqc2+ffvYu3cvhQoVom3btsyaNQtDQ8P39pFYuXIlo0aNYsCAAQAYGRmxfv16ChYsmKXanj59SlRU1D9et3+rRIkSlC1b9r3t3vb569GjB40aNVLbLVq0iLCwMHUMeMbwus8//xwbGxtWrFjBsGHD+PXXX9Xhe+860iE+LBLUH7i3/ZCbm5u/8zDm4sWLWbx48Vvnv2kv4r9o2rRpREVF8eLFC3799Vfu3bunztu9ezenTp3C1dWVefPmaTyvWbNmNGzYkNjYWIoXL862bdvUeampqejo6KCvr4+joyOhoaFs3bqVEiVKZLmuDyFo9u3bx7lz59i4cSOPHj0iJSUFSD/fXa5cOQYOHIiVlRW6urps2rSJ3bt3Y2pqqnGFr/PnzzNq1KhMfSQ2bdpEWFgYkyZNwsTEhNmzZzNhwgQOHTr0xl7Xr3r69CltOn7J89iEf/ku/HPGRQ359cDP730P3/b5s7a2xtraGkg/Xx8WFkatWrXUznDvG173viMd4sMiQf2B+hB+yD8UrVu3Vt/LDh060K1bN+7fv8+CBQuYPHnyWw8X/vTTT8yfPx9Ifz9WrlwJQJEiRXB3d2fixIl06tQJSB8mldWLxnwoQfPo0SOSk5MZOHCgxnQXFxfWrl2rdryC9I2XcePGqadS4O19JCIjIzl+/DhFixZl0KBBAPzwww9cu3YNf39/6tev/87ao6KieB6bgEGL+RQsVTXb6/5vJYYH8fzYTKKiorL0HXnT5+9VGUPLMo4uvG94XVaOdIgPiwT1B+hD+SH/UKxZs0Y9PH348GFatmyJt7c3tWrVomHDhly9ehVIv2Tnw4cPqVSpEpB+aLly5cpcu3aNtWvXsnTpUn788UcA1q1bR1JSEgsWLCAuLo5FixYxceJEfvrpp/f2rP9Qgubzzz/XOCc6d+5cIiMjmT59OnFxcYwePRp7e3v09fXVS5vWq1cPeHcfCWNjY4yNjXn+/DnLli2jZMmS+Pv7Y2BgkK1e6QVLVcWwrPk/exP+paRstH3T569169YAPHjwgGPHjlG6dGnat2//1td4dXjd+450ZKczntAOEtQfoA/lh/xD8emnn6r/HzduHHv37uXx48c8fvyYVq1aqfP8/f3p3LkzFy9eBNJ7AZctW5bGjRtz+PBhrl+/zq1bt1AUhevXr2NmZqbuHW3cuBE/Pz+ePXuW5fdM24OmRo0a1KhRQ328dOlSABo2bEhaWhp79+5lzZo1vHz5krJlyzJmzBj1giPv6iNhb2/PunXrWL58OT/++CNpaWnUqlWLMWPGUKpUqRxdT23wps9fRlBv27aNtLQ0+vTpo57XzxheFxUVRUxMDMWLF9cYXnfr1q13Hul4W7+FN8k4ZXH//n0URVH/PpB+U5OLFy8SFhYGoHG0ZM+ePWrHxgzm5ubs378fSO9E9/fff2vMnzp1Kv37989ybblV36NHj2jevPkbl/fqa+QlCeoPmLb/kGu7P/74g0OHDmFnZ4eiKGrvWDMzM3r06EF8fDwAgYGBrF69mipVquDq6grAhAkTqF69OuXKlcPf35+7d+9SuHBhPvnkE5KTk9HX1ycwMJBNmzYRFxdHREQEJUqUwNTUNN/WN7e93os645Dtm7yvj4SdnR07duzIsdq00bs+f5C+Qb5nzx6KFCmiMcQN3j28rlq1am890pGVy6e+KikpiSZNmvDbb79lOs+dcVOTDRs2vPX5I0aMUDfmihcvrjHP2NiYmTNnqo/r1KmTrdpyq76SJUvi5uamtrl8+TLe3t5qR778IEEtPlrGxsbcvn2b3377jdTUVMqUKcOQIUMYNWqU2nMWUC+hamRkpG5pFy9enB9++IGoqCiKFClCw4YNGTlypHrOcPXq1axevZr169ejq6vLp59+yoQJE7I9vEhbSR+Jf+9dnz9Iv157fHw8/fv3Vz9XGd41vO5dRzqye+XBjFquXLmSKQhXrFhBYmLiO4Owfv362NnZaVzaOEPhwoVp0qQJhoaG//h7kRv1FS5cmHbt2qmPd+/eDWT98rO5QYJafLQsLS2z1NHG3t4+0yGv2bNnM3v27Lc+p2nTpjRt2vTflqiVpI9Eznjf52/YsGEMGzbsjfOyM7wuq+PFc4OLiwuKolC+fHnGjh2rdq6E9IvR2NnZUaBAAerXr8+8efPy/KJL76oPICAggL/++otKlSppnAbLaxLU4qMke4T/nPSR+Pf+65+/ypUrM2XKFKpUqcLDhw9Zvnw5U6dOxdLSkmrVqtGiRQu6du2KkZERhw4d4tChQ0yZMkXtjJnb3ldfhoxhlwMGDMjXyytLUIuPjuwR5gzpI/HPfAyfv/r162sMozt9+jR//PEHgYGBVKtWjX79+qnzrKysOHToUJ521HpffZB+w5tDhw5RokSJfL+mhAS1+OjIHqHITx/S5+/ChQsEBwcTGRkJpF/t7MGDB3Tr1o3Dhw9rXLXvp59+wtTUlCZNmjB79mwKFSpEzZo1CQkJ4ezZsxQsWJC6devy4sULBg8eTPPmzTExMeHo0aPA/w3dy47cqC+Dt7c3ycnJ9OzZ843n2POSBLX4aMkeochPH8Lnb/fu3RrXHM+4E1m3bt3eeVMTMzMzfvzxR3bu3Imuri5WVlaMHj2aChUqkJiYSNmyZdm+fTuRkZHqHuukSZOyvR65UR+k34hl586dFCxYkN69e2e7rpwmQZ1NO3bsYMuWLYSFhWFubs7MmTPztdu+EELklncNo3tXJ7WePXvSs2fPN84rWLAg7u7uOVFertQH6T2/Xx/nnZ8kqLPh8OHDLFq0iLlz52Jtbc3333+Pi4sLv/76q3p/YCGE+NBpe2c3ba8vp0lQZ4OnpydfffUVXbt2BdIvJHDq1Cl2797NkCFD8rk6IYT497S9s5u215cbJKizKCkpiRs3bjB06FB1mq6uLo6Ojly5ciUfKxNCiJyj7Z3dtL2+3CBBnUXPnz8nNTU10yFuExMTjVsjvkvGhfNTU1P/VS2KolDI0BDd6GAooLy3fU7Tjb5PIUNDFEV547pIfVKf1Pfh12egr4NBftSnr4PeB1xfVmU899UbqryNjpKVVoLQ0FAaN26Mj48Ptra26vSlS5dy4cIFfvrpp/e+RlJSEtevX8/NMoUQQnxALC0t1RuuvI3sUWeRsbExenp6REREaEyPiIjI8h19ChQogKWlJbq6uujo6ORGmUIIIT4AiqKQlpZGgQLvj2EJ6iwyMDCgbt26nD17Vr1NXFpaGmfPns3yODtdXd33bjkJIYQQr5KgzoYBAwYwefJkLCwssLKy4vvvvyc+Pj7fLy8nhBDiv0uCOhvatm1LZGQkq1atIiwsjNq1a7N58+b/5M3shRBCaAfpTCaEEEJosfy7b5cQQggh3kuCWgghhNBiEtRCCCGEFpOgFkIIIbSYBLUQQgihxSSoRZ6SQQYiv8ln8L/vv/Y3lqAWeSIhIYGkpCSePHlCYmJifpeTyX/ti52f0tLS8ruETBISEoiPjyc2NlbrL98rn8V/JikpiejoaACt/xtnl4yj/g948eIFsbGxxMXFUb169fwuJ5O7d+/i7u5OcHAw9+7do2bNmjg5OTFx4sT8Lg2AR48ecerUKaKiovjqq68oXbp0fpek4cWLFzx//pwiRYpgbGyMrq52bV9HRUURFRVFamqq+vlLTU1FT08vnytLFxQUhIeHB4mJidja2tKrVy+t+yGPjY0lIiICExMTihYtmt/lZPL48WOOHj1KdHQ0zZo1w9raOr9L0hAUFMS6deu4f/8+nTp1olevXvldUo6SK5N94DJCUF9fn0qVKjFu3DjS0tK05sf81q1b9OrVi44dO9K4cWNKlCjB3r17+f777wkMDGT16tXo6+vna32jR4+mXr16FC5cmBIlSuRbLW9y584dpk+fTkxMDJGRkYwYMYKOHTtSsmTJ/C4NgNu3bzNz5kzCwsLQ09OjSZMmTJ8+XWtC+tatWwwcOJAOHTpgY2NDixYttC6k7969y3fffUdsbCzW1tZMmjQpv0vSkPEdsbOzo2bNmtSsWTO/S9Jw69YtXFxc6NChA+3bt6dBgwb5XVLOU8QHKyAgQHFwcFDc3NyUy5cvq9MfPXqUj1X9n4iICOWLL75Qli1blmm6t7e3YmNjo4wdOzafqlOUe/fuKfb29sry5cuV5OTkfKvjbfz9/RVbW1tl/vz5ypkzZ5Tx48crtra2yunTp/O7NEVR0uuzsbFRFi1apJw6dUqZNm2aYmFhofz888/5XZqiKIry+PFjpXnz5srixYs1pqelpeVTRZkFBAQojo6Oipubm+Lv769Of/jwoRIfH5+PlaULCgpSHBwclGXLlilJSUn5XU4mISEhSvPmzZVFixZpTNemv3FOkKD+QD169Ehp2rRppg/oli1bFHNzc+XgwYP5VNn/uXHjhtK+fXvl1q1bSkpKiqIoipKamqooiqLExMQo69atU6ytrZXffvstz2tLTExUpk+frkyaNEnjB1FbvuC3bt1SbG1tNTZyAgMDlbp16yrz58/Px8rSBQUFKZaWlsqqVavUaYGBgUrt2rWVFStWaLTN+JvntV27dim9e/dWQkJC3vt3zY+/+9s2JDw8PJSmTZsqR44cURITE/O8rgzJycnKrFmzlNGjR2vld0RRFMXHx0fp3r278uzZs/e21aa6s0s7jo+KLFP+f5eC//3vf1SvXp2BAweq87Zs2cLq1atp0qQJc+fO5dChQ/lVJgABAQHcv3+fWrVqoaenh6Io6iH5YsWK0b59ewoUKMD9+/fzvDZ9fX2uXr1KlSpVMDQ0VKdnHBbN6BCVXx3ffvjhB+Li4mjYsCEpKSkA/PLLL6SkpBAfH8/WrVu5efMmDx8+zNO6FEUhJSUFHx8fChcujKmpqTrv2LFjpKWlce/ePX788UcOHz6s8TdX8rg7zN9//01ycjLlypXLdLg7o5a4uDiio6Pz5XD4qVOnKFu2LAMGDFCnrVmzhk2bNlG2bFlmzZrFqVOnSEpKyvPaIP07cPXqVWrWrPnO70h+1Qdw6dIlChQooPE5zJDxN86oT9tOeWSHnKP+wGR82C5cuACgdnyKiIggODiYTZs2UbVqVTw9PZk9ezapqal06tQpX2qtXLkyAEePHqV169aZviiVKlWiUqVKhIaG5mldqamphIeH8+TJE6pWrQpASkqKxg3cM8LF29ubL7/8EiMjozyp7eXLlxQpUoQ5c+YQFhbGuHHj2LhxI2fOnOH7779n1KhRlCxZktOnT/PLL78QGRnJZ599RvPmzdX7pOemlJQU9PX16dmzJwkJCezdu5eCBQvy/PlztmzZwqBBgzAzM+PgwYM8ffoUd3d3KleuzODBg7G3t8/1+jKkpaVRoEABChYsCEBycrJGX4iMz+LWrVspU6YM3bp1y7PaMpw7dw5dXV31OxwXF0dcXBwrV67EwcGBqVOnMnXqVObNm8fnn3+e5/1OXrx4wcuXL9XP/uvvYUY9mzZtokWLFpibm+dpfQCFCxcmKiqK+Ph4ChUqpDEv4288depU7OzsPugOZrJH/YHJ2EqMj4+ncOHC6jQTExMmT57Mp59+SqlSpejTpw81a9bk6NGj+Tbco2LFihQtWpR9+/bx+PFjdXrGlnh0dDQFCxakbt26eVJPxpa1np4epqam1KhRAx8fH6KioihQoECm9+nGjRv873//IyYmJk/qCwgIYOLEidy7dw+AtWvXYm1tzVdffcXmzZtZsWIFo0aNomfPnqxfv57FixczbNgw9ahFbvPz86Njx45ERUWp4WtmZsaGDRtYvnw5a9euZeLEiXTo0IE1a9awe/duunXrhpGRESYmJrleH/zf90NXVxcrKyvOnz/P33//jb6+PmlpaRp/46ioKO7evZsvHfMURUFfX58CBQqQmppKamoqhQsXZvz48Tg4OACwaNEiKlSowLFjx/IspJOTk9Xvp5GREYULF+bEiRNA+lGo1NRUjfbXr1/n1q1bFCtWLE/qy5BRY7ly5Xjw4AFnzpxRa3t1eGBsbCwFChSgbNmyeVpfTpOg/kA5ODhw+vRpfv/9d3XL0dDQUP0hMjY2pmzZsnz66af5dsinbNmyzJkzh9OnT7Ny5Uru3LkD/N+WuKenJ8+ePaN+/fq5XsuDBw9YunQpv//+u1qDo6Mjfn5++Pj4EBMTk+l9On78OMWLF8fY2DjX6wsICKBLly6YmZlRrVo19Udnw4YNtG/fnqSkJPT19TUOM9aoUYPu3bvz/fffq0cvcrO+vn370qhRI0qUKIGiKFSoUIEhQ4Zgb29PtWrVuH37tsZz9PX1GTx4MIsXL6ZGjRq5Wl9iYiJJSUnqBmFaWhqtWrXCwsKCb775Bl9fX3R1dTX+xl5eXgQFBeXZhuKrdHR0qFq1KhcvXuTOnTvo6empRwEg/ahPQkICderUoU6dOnmysf3gwQPc3Nw4e/YsL1++pECBAvTv358LFy6wZMkSALU3f0Y9J06cIDExMU+GlGX8jcPDw4mLiwNgyJAhVKtWjaVLl3Lx4kUSExPR1dVV69u6dSv+/v7UqVMn1+vLVXl8Tlz8A3Fxccrz5881OpZcvHhRadWqldKjRw/l7NmzGu3T0tIUNzc3pUWLFsqDBw/yulwNKSkpyo8//qjUqVNHad26tTJ16lTFzc1NGT9+vPLpp58qN27cyPUaAgIClKZNmyoTJ05UfvjhB415AwcOVKytrZXFixcrjx8/VhQlvTf4ggULlAYNGii3bt3K9fpu3rypWFlZKW5ubhrTIyMj1f8PHTpU+eyzz5RTp06pvW8zOsfkdieZt9X38uVLRVHSOzbOnDlT+eqrr5Rt27ap8/OqJ31gYKAyfvx4pX379spnn32mdO/eXdmyZYuSlJSknD9/Xvn8888VOzs7Zfv27crFixeVo0ePKtOmTVPq1aun3Lx5M09qjI2NVV6+fKmEh4er0x49eqR07NhRadq0qfLw4cNMz3Fzc1OaNWuWJ99hf39/pWnTpsqoUaOUI0eOqNOfPHmiTJs2Talbt64yd+5cJSIiQklMTFRu3bqlLFy4UKlfv74SEBCQ6/UFBgYqo0ePVjp27KhYWVkp7du3V9auXasoSnqn1Xbt2ilOTk6Ku7u7cuvWLeXQoUPK7NmzFTs7O43e9B8queCJlgsMDGTZsmU8fPiQ8uXL07lzZ9q2bQvAvn37WLZsGSVKlKBnz540atSI27dvc/LkSY4cOcL27du1Zkvy6tWrbN68maCgIIoVK4a5uTm9e/fO9Qu0BAUF0bt3b7p06cLw4cPV0wWvGjduHOfOnSMpKYlSpUpRuHBhkpKSWLZsGbVr187V+u7evUuXLl0YMmQII0eOVKdv2bKF5ORk+vTpQ5EiRQAYNmwYN27cYPbs2TRp0kTjnHpuCQwMpHPnzowePZohQ4ao07du3crdu3eZPXs2BgYGPH78mI0bNxIYGEiTJk002uamW7du0bt3b9q2bUu1atUwMTFhx44d3L17F3t7e5YvX05AQACenp4cPXoUfX19ypYtS8WKFZk8eXKenDIIDAxkyZIlhIWFAfDNN9/QtGlTUlNTOXbsGN999x0pKSmMGjWKOnXq8PjxY7UPQl58h4ODg+nVqxddunRh5MiRGh3HAB4+fIi3tzc7duygSJEi6OjoUL58efU7ktvnpjP+xu3atcPCwgIdHR1OnjzJsWPH6NixI1OmTCE5OZnp06dz/fp1oqOjqVixItWqVWPixIl58jfOdfm9pSDezt/fX6lXr54ybdo0Zdu2bUrTpk2VNm3aaOyF/vrrr8rAgQOVunXrKjY2NkqLFi2UAQMG5MlWbnalpKSoe395MWQnNTVV+fbbb5UpU6aow8MURVGeP3+u3Lt3Tzlx4oR6lOL8+fPKli1bFDc3N+W3335Tnj59muv1xcXFKT179lSaNGmisdW/ceNGxcLCQjlz5oyiKJp7pj179lRatWql7s3mpvj4eGXChAmKmZmZ8uLFC4366tWrp9aX8Td9/PixMn78eKV///5KVFRUrtcXHh6utG/fPtM4/aSkJGXZsmXKZ599pkybNk19/wIDAxVfX18lJCREY31y082bN9Wx8OvXr1f69++v1K1bV7l69aqiKOnfib/++ksZMmSIYm5urpibmyutWrVSBgwYkCdHc9LS0pT58+cr48aN05geExOjBAQEKGfOnFGePHmiKIqiBAcHK56ensqGDRuUP//8UwkNDc31+sLDw5VOnTop3333ncb0jGsxWFpaKrNmzVKnP3z4ULl69aoSGRmZZ3/jvCBBraXu3Lmj2NraKu7u7uq0//3vf4qZmZmyf/9+jbbPnj1Tbt26pfz2229KUFCQEh0dndflZsmrh2jzYkxjSkqK0rdvX2X27NnqtGPHjimTJ09W6tWrp5ibmyudO3dWLl26lOu1vM3hw4eV7t27K+PHj1cePHigeHp6Kg0aNHjnRU1CQkLypLa0tDTl/PnzSq9evZS2bdsqiqIo3t7eSoMGDZQ///zzjc95/Phxlsa05gRfX1+la9euSlBQkLohlnFaID4+XpkxY4bi4OCgcTGgvJQx7n3jxo3qtAMHDii1a9dW9uzZk6n91atXlQsXLuTphkRaWpoydOhQZcmSJeq03377TXF1dVVsbW2VTz/9VGnZsqVy/PjxPKnndVevXlXatWunBAYGKmlpaRq/G7GxscrGjRsVMzOzfLkWQ16S4VlaKCkpienTp2NoaEjr1q3V6X5+fgBERkbyxx9/ULNmTcqVK4epqSmmpqZaf4jn1Y48udnBLWOolZ6eHlZWVly4cIHDhw9z69YtDhw4gIODA/Pnz8fOzo7evXuzY8cO7Ozs1OcripKr9SUmJpKcnEyRIkX4/PPPMTQ0ZO3atYwePZr79+/j4eFB/fr1NS4Fu2PHDoyNjWnbti3lypXLtdogfURBQkICRYoUoUGDBkydOpW5c+fSoEEDUlJS+P7777G0tNR4zqZNm7C3t8/Ta0Dfvn2bO3fuYGJionZyyujdbWhoyLhx4zh69CiXLl3C1tY2z+qC9JuAbNq0CR0dHRo3bqxOv3//Pmlpafj6+lK5cmUMDAzU99LKyirP6ssYzqSjo4OxsTFHjhzh008/5ezZsxw9ehRHR0eWLVuGiYkJHh4e7N27lwYNGlC4cOE8HSbm7+/P06dP1VNkaWlp6nezSJEiNG/eHA8PD54+fZpnNeUH6fWthQwMDJg+fTolSpRg3bp1PHz4kM2bN+Pl5UWrVq2Ij49nypQpjBs3jl69erFt2zaCg4Pzu2yt8PjxYwYMGMCDBw8AcHZ2plSpUixdupQDBw4wYcIExowZw+eff06ZMmVo3bo1jx8/1riwSW6G9N27dxkzZgw9e/aka9eunDlzhqZNmzJ69GjS0tKwsrJSz6Nn/CC6u7uzdOnSPDufOm7cOHr27ImLiwu7d++mbt26zJw5E2tra4oWLUqVKlUA1AuxrFmzBjc3N3XMcl4xMjJCURQCAwOB/xuWk/G+FS1aFBMTE2JjY/O0LkgfgdGhQweaNm3KtGnTePToETt27GDLli10796dwoULs27dOvr06cOkSZOYP38+L168yJPanjx5wvTp0zl69CgAkydPpkqVKnz77bccO3aMyZMn880336g33yhTpgzPnj2jaNGieT6Wu3r16sTHx/Pbb78BZFp+9erVKV26tMbwz/8i2aPWMhl7UVZWVixatIhJkyYxdOhQwsLCWLdunTrGslu3bmoHnl9//ZXmzZvnc+XawdDQkIcPHzJ27FjWrFlD/fr1qVWrFomJiRgaGmqM91QUhdDQUPXKabktICCA3r1707JlS2rUqMGlS5cYP348mzZtwtnZmeTkZDZu3MjmzZvp27cvNjY2rFq1Ck9PT3bs2JHrQ5wCAgLo1asXzZs3p127dhw/fpx169ZRpEgR2rRpw7Bhw1i+fDndu3dn+/btmJiYsGLFCjw9Pdm9e3eeX/CiYcOGGBsb4+Hhwbp169DV1VX3uHR0dHj58iXGxsbqTSRy+0jJ65ycnNDT08Pb25sePXoQHR3Nzp071Q6KiYmJXL9+nYMHD/L3338TFRWVJ+ORIyIiuHv3Lvv27cPQ0BBnZ2c8PT15+PAhxsbG6lCrjPcrOTmZGjVqkJSUhIGBQa7X96qSJUtibGzMgQMHqFGjhnqBooyNsqioKIoWLZrpCM9/Tr4eeBeqFy9eKBEREcrVq1eV6OhoJTY2VlGU9HM0rVu3Vrp37/7WoUz/pU4T/1RCQoL6/7CwMKVDhw5Khw4dNIa9vHp+KyEhQXFzc1MaNmyoBAYG5np9t27dUmxsbDSug/3ixQulcePGyujRo9Vpx44dU7p27apMmTJFmThxomJpaalcv3491+sLDAxUrK2tNa7dHRoaqjRu3FiZNGmSoijp79/ly5eVnj17Kl988YWyYMECxcrKKk/qe11GZ8SMoX9jx47N1MEuY3hTXp3Tf/HihRIeHq7cvHlTCQ4OVqdfuHBBGT58uNKyZUuN73BGJ7ekpCSNz29u1pfRefLq1atK7969lcGDBysnTpxQ27zayTM+Pl5xc3NTHBwc8uQ7kuH1/is///yzYmZmpkyZMiXTb6C7u7vSrFkzdWjlf5UEtRa4ffu2MnDgQKVVq1ZK3bp1FScnJ2X8+PFqyFy5ckVp2bKlMnr0aLW3qKLk3ThVbRcQEKC0a9dO7YWsKOkd7Dp06KB06tQp0zjUvXv3Kq6urkqjRo3yZBx3amqqMm7cOMXMzEztKZvxtxs+fLgyefJkjTHyx48fV5o1a6bUr18/T+pLSkpSRo4cqTg4OCh//fWXRn2TJ09WRowYoVHflStXlK5duyp169bNk5B++PDhW8cSR0REKOvXr1dsbW2Vdu3aKd9++63i7u6uTJw4Mc/eP0VJ/w737dtXad++vWJmZqbUq1dPGT9+vHL//n1FUdKvezB8+HDliy++UL/DqampeXajiLt37yo9evRQtm/frt5g49WwPnnypEb7LVu2KFOnTlUaN26cJ2PNnz59qvz+++/q49c7jm3btk0xMzNTPv/8c2XBggWKm5ub4urqmmfXYshvMo46n92+fZuePXvSpUsXGjRoQKVKldixYwd//PEHiqLg5eXFJ598gq+vL66urtSpU4c+ffpQr169/C5da4wcOZLjx49TqlQpvvvuO/X0QFhYGC4uLujq6rJ69WoqVarE7du3+emnn0hKSqJ///7qobTcFhERwfDhw4mLi8Pd3Z0aNWrw7NkzWrZsyeTJk+nZs6fGodmzZ89SsWJFKlWqlCf13bx5k+XLl6Ojo8NXX31Fq1atePbsGS1atGDy5Mka10lWFAVfX1/KlSuX65dmTEtLw8XFhTt37vDDDz+88QpsL168ICAggA0bNvDs2TMMDAywsLCgb9++uT5OH9K/wz169KBr1640btwYQ0NDzp07h7e3N+XKlWPu3LlYWVlx7tw5tm/fzrNnz5gyZUqefYeTk5OZMGEC//vf/2jSpAlNmzalU6dOGBoacu3aNb777jsKFSpEz549adKkCVFRUXh4eBAdHY2Li0uuf0eSkpIYN24cERERDB06lKZNmwKZT1X88ccf7Nu3j2vXrlGyZElq166dZ3/jfJefWwkfu6ioKKV79+6ZbnOnKOnDOFq0aKG0b99e3Qu7fv260qBBA8XV1TVPDpV9KI4fP664uLgoAwcOVKysrDSGDr26Z51xeCwqKkqJi4vL8zojIiKUrl27Kl988YVy7tw5pWnTpsqcOXM02uTHrfgylunv76/07dtXGT58uOLj46M4Ozsr8+bN02iXH/WFh4crX331ldKuXTuNQ8oZNb0qMTFRSUhI0Bg3n5uio6OVXr16ZfoOJycnK5cvX1YaN26s9OzZU63n3LlzSt++fZXevXsrCQkJefZ+Hj16VLGzs1O++OILpVevXsquXbveuGf9xx9/KIqS/r7m5Xfk2rVrysCBAxUXFxfl2LFj6vTXjzq8+jiv/sbaQII6Hz148EBp3769cunSJfXc0KuHszPGrO7atUuddvPmTfVwmkgXFBSktGrVSvn5558Vd3d3xcrKSj2EqyjpYd25c2fF2dk5389lRUREKF9++aViZmamjB8/Xp2eX/dszpDx43fz5k2lb9++io2NjTJw4EB1fn6fZomIiFC6dOnyxrBWlPTzqZ6ennlyEY5XPXjwQGnVqpVy7tw5RVEybzj8/vvvSt26dZUtW7ao0y5evKheRCS3ZXyuXrx4ocyZM0fZsWOHMn78eKVTp06Zwrp///7K119//c4x/Lnh9Q3F18M6Y35iYqLi7e2d6UI7HwMZnpWPHj16pI4DzRh28OpdnHr16oWpqSmXL18G0i/UX7t27Vy/AYO2e/3+t1WqVKF37974+PjQqVMnOnXqxIgRI/jrr78AMDU1ZcOGDVSoUCHT3X9yk/LKWaWMoUwlS5Zk06ZNfPrpp+r9uiHzsJPc9KZ7bGe8L7Vr12bWrFlYWVmho6Oj3jnpTXcXy0slS5bEw8ODggULMnLkSI3hiBmXsly8eDEvX77M07qCgoIICQlRh6y9eucmABsbG2rUqKEOFwSoV69erp8yiIuLIz4+Xr1BRdGiRTEwMODUqVMsX76cWrVq8eOPP3Lw4EESEhKwsrJi1KhRGBkZ5fmhZB0dHRRFwdzcXL0c6A8//MCxY8fU+YmJiSxcuFC9o1jG9I+FBHU+MjY2xsDAgLNnz2p8wTM+uJB+B6qMH9G8GEKk7W7dukWbNm3w8PDg5MmT6vSGDRtSpEgRYmJi1Pv3jhw5kjNnzgDp9+328vLK9XO+SvpRKuD/fkgyLsASEhLCgQMHMDY2ZuXKlRgaGjJmzBju3r2bqzW9KjQ0FFdXV86dO6dOS05OpkCBAjx58oRjx45RvXp1pk6dSnJyMrt27eLIkSMa65MX3raRs2XLFgwMDBg1ahT3798nNTWVJUuW8PPPP7Nnz54863OQoXr16hQoUIDdu3cD6d/RV2svXrw4JiYmREdH51lNd+/excXFhZkzZ3Lr1i3i4+MBmDhxIk+fPuXw4cMsWLCAihUrsnPnTg4dOkR8fDz16tVj5cqVuX5BnfdtKE6bNo2UlBR8fHw4fvw4AMuWLWP//v34+Ph8lDsqEtT5yNzcHEtLS7Zv386jR4/U6cr/70SRseeYMe4yP/dotEFaWhoeHh6EhITwxx9/sHz5csaMGcOff/5JlSpVqFmzJm5ubgDMnz+fjh07MnDgQM6fPw/k/oZOUFAQCxYsYPTo0WzdulWtuUCBAjx+/Jju3btz7do1FEWhZMmSbN68mfj4eKZPn05ycnKu1pYhKSmJ0NBQPD09uXjxIpB+Na+HDx/SoUMHLl26RFpaGubm5kydOpVnz55x5MiRPNlTzcpGTokSJdi8eTMFCxZk1KhRuLq6smfPHnbs2JEvN6ApUqQINjY2HDlyRD2Ck7GhnZaWpoaSjY1NntSTnJzMihUruHLlCpcuXWLo0KGsWLGCHTt2oK+vT+PGjbl27RoGBgYsXbqUypUrs2nTJvXiJ7k9TjorG4pmZmbqhuLOnTvp378/u3btwtvbGwsLi1ytT2vl/dF2oSj/1xHi8uXLirOzs9K5c2fl+vXr6rnA1NRUxd3dXWnYsGG+36pSm4SFhSkuLi5KkyZNlDNnzijjx49XhgwZonTq1Enx9PRUmjdvrl67Oy4uTpk/f36ejAH19/dXPvvsM2XEiBHKuHHjlLp16yqbN29WFCW9M1TTpk2VGTNmZDqv9vz58zz/+wYFBamd73x9fRVFUZSGDRsq06dPz3TrzFu3bimPHj3K9Zru3bunzJs3Txk5cqR6Pjfj/OqjR48UJycnZf78+WpdERERSqdOnRQzM7M8u1Xl21y8eFGxsrJSvvzyS41bRKampiorV65UGjZsmKf9Svz9/ZWBAwcqU6ZMUebPn694e3srjRo1UqZMmaIOE8w4p56QkKBMmTIlzz6DDx48ULp3764MGTJEuXDhgsb0evXqKYsXL1b/7v7+/krnzp0Ve3v7fP8b5zcZnpWHlFeGG2TsKaSkpPDnn3+ycOFCnj9/Tt26dTE1NSU2NhZfX182b96cLze212aRkZG4uLhQuHBh5s2bh7GxMdu3b+ePP/7gxo0beHt7U79+/TyrJyAggO7du9O/f3/GjRtHWloa3377LXp6ekycOJHQ0FCOHz9O//798/zqWG8THBzMggULAGjdujVlypTByclJPVeuvLZnm5sCAgIYMGAAdnZ2FCxYkP/973+MGzcOFxcXIiIi6NatGw0bNmTevHka9URGRpKYmJjrh2oh/XDt65dIzfgOA/z9999MmDCBlJQU6tSpQ4kSJUhKSuLSpUt4eHjk2Xc44/N148YNli5dSpEiRejRowc2NjZ4eXkRHBzMwYMH8fT0VIcx5rWMz56iKIwZMwZra2ucnJxo0qQJ8+fPV49I6OjocO/ePQwNDSlfvny+1KotJKhz2Zt+8DK+4I8fP+b69eu0adOG8PBwNm3axKNHj0hKSsLa2poOHTqonVSEpoywTklJYd26dVSqVInHjx+TkJBA9erV8ywQnzx5QufOnbG3t2flypXq9HHjxnHv3j0SEhIwMzOjadOmdO7cOdfryY7g4GAWLlyIoigMHTpU3bjJy42JD2EjJzQ0lIULF9KjRw8+++wzIP1wrb6+PiEhIdy8eZMWLVpw584dTpw4wdmzZzE0NKROnTp07Ngxz7/DGe/TzZs3WbJkCTo6OgwfPhx7e3sgfcx8ft+nXps2FD8EEtS5KCgoCG9vb0JDQ7Gzs2PgwIHqtbwfP37M119/TevWrZkxY0Z+l6rV3nQkAtKv8ztw4EDi4+PZuHFjvnQyefToEWPHjsXU1JRBgwZRr149Nm3axLp16xgyZAimpqZ4enqSmprKypUr8/x62O8TFBTEt99+i6IojBw5UuMuYrntQ9nIefjwIZMmTcLIyIjBgwerGzQPHz6kc+fOdOvWjUmTJuX5DSvg/Xv6t27dYuHChRQoUIAePXrQokULAI07s+UXbdhQ/FBIZ7JcEhAQQM+ePXn69CkGBga4ubmxZcsWdHV1iYiIoE+fPjRp0oTp06cD0lHsdUo2OhYVLlyY0aNHc+/evTyvs2LFiixbtozk5GQ2b97MjBkz2LZtG2vWrGHEiBF069aNzZs3c//+fa5evZrn9b1P1apVmTFjBvr6+ixZsgRfX988W3ZqaioVK1ZUDxFD+u0yT548SevWrRk0aBCBgYFs2LCBgICAPKvrdZUqVWLx4sWkpqayfv169e/Yo0cP2rRpg6urqxp6r47eyO3vdHY6ZqWkpPDzzz/z66+/Ank7HPBtqlSpwtSpU1EUhfXr16vDUCWk3yBvToV/XPz9/RUrKyvFzc1NUZT0TiXz5s1Tvv32WyUxMVF58OCB4unpqSjKxzVoP6uy27EoMjJSadmypdK9e3clKSkp32oeMGCAYmVlpdaclpamJCUlKU+fPlU6duyo0dFI2wQGBiqjR4/O8wvCZHRsGzZsmDJ9+nTFwcFB44Ibjx8/VszMzBQfH588retNMmp1cXFRdu3apfz+++/5eqGaf9Ixa/To0eoNf7RFUFCQMnToUOWrr75Srly5kt/laCUJ6hwWEhKi2NvbK2PGjNGYPnbsWKVjx45Kq1atlNGjRyt79uzJpwq124fUe/p19+/fVwYOHKgMGjRI44cz4w4/eXUXp3/q1Rtv5KUPaSMnKChIGTx4cKa/cX5tcGtjD/5/Ir82FD8Uco46h33o5yzz04fQseh9Xu3ROmHCBP766y9Wr16Nj49Pvnfg0WYPHjxg7ty56OrqapyvXLlyJQcOHFBvcKEN8vO8/pv8Vzpm5cf9rj8UEtS5IOOLo6+vj4mJCSdOnGDp0qU4OTkBEBISQrNmzZg7dy7du3fP52q1w4fSsSgrgoODWbx4MdeuXSMmJgYfH5+P90IN2fAhbeRk/I2fP3/O1KlT8+yCJu+qRzpm/Xflf4+C/6AqVaowffp0EhMTOXjwIIMGDcLJyQlFUUhOTkZPTw8zMzOMjIzyu1St8aF0LMqKKlWq4OrqirW1NXv37pWQzqIqVaqoHdsGDRrEypUr+eGHH7QupCG91kmTJlGmTBlKly6d3+VIx6z/ONmjzkUf0uE8bfBfOxKRMdZWZM+9e/f47rvvGD9+PDVr1szvct5J2w7XatuevsgZskediypXrszMmTPVrdyb/6+dOzhiEASAKEotlAxHhrasx3tuxMis8b0m/rAox1HGGGXOWXrvIv3h35YIkf5OrbW01uIjXcr9b2OvSjvp8xtO1Bu4s1xjiYBr0k76XCPUmzxpzkvwpA+LAO4k1Bu5s1xjiQAQasJZIoC3E2riWSKANxNqAAjm9ywACCbUABBMqAEgmFADQDChBoBgQg0AwYQaAIIJNQAEE2oACCbUABDsBKe6iDVR6hx4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tags = [tag for sample in data['train'] for tag in sample['tags']] # flatten the tags\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "tags = list(tag_counts.keys())\n",
    "counts = list(tag_counts.values())\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "colors = [\"#fc0000\" if tag == 'PER' else \"#0080ff\" for tag in tags]\n",
    "bars = plt.bar(tags, counts, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height + 5, str(height),\n",
    "             ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
    "plt.ylabel(\"# of tokens\", fontsize=10, fontweight='bold')\n",
    "plt.title(\"Distribution of NER Tags in training Set\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298b324",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "1.  *Class Imbalance:* The **'O' (Outside)** tag dominates the dataset. Non-entities make up the vast majority of tokens. Hence a model trained with standard accuracy as the sole metric might converge to a local minimum and it may predicts 'O' for everything.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3dc068",
   "metadata": {},
   "source": [
    "In the example below, we demonstrate this behavior using the word \"embedding\". BERT splits it into smaller units, adding `##` to indicate that a token is a suffix of the preceding part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ace0d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: embedding\n",
      "BERT sees:     ['em', '##bed', '##ding']\n"
     ]
    }
   ],
   "source": [
    "# Pick a word that BERT will likely split\n",
    "word = \"embedding\" \n",
    "print(f\"Original word: {word}\")\n",
    "\n",
    "# Let's try a third one that is currently being used with deep transformer models.\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Use the tokenizer you loaded earlier\n",
    "sub_words = tokenizer.tokenize(word)\n",
    "print(f\"BERT sees:     {sub_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6040c6",
   "metadata": {},
   "source": [
    "*Sub-word Tokenization:* Unlike traditional LSTM models that often use word level tokens, Transformer models like BERT use **sub-word tokenization**. This allows the model to handle rare words and significantly reduces the vocabulary size by breaking unknown words into known sub-components. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704aa6d1",
   "metadata": {},
   "source": [
    "### 0.3 Label Encoding\n",
    "To train the model, we must map the categorical string labels (IOB tags) to unique integer IDs. The `tag2id` defines the class indices for 9 output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b24dbe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# tag to id mapping and vice versa\n",
    "# \n",
    "# for tokens that does not have a tag, we will use -100 as the corresponding tag ID\n",
    "#\n",
    "\n",
    "tag2id = {\n",
    "    'O': 0, \n",
    "    'B-LOC': 1, 'I-LOC': 2,\n",
    "    'B-ORG': 3, 'I-ORG': 4,\n",
    "    'B-PER': 5, 'I-PER': 6, \n",
    "    'B-MISC': 7, 'I-MISC': 8\n",
    "}\n",
    "\n",
    "id2tag = list(tag2id.keys())\n",
    "\n",
    "print(id2tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bce302d",
   "metadata": {},
   "source": [
    "### 0.4 Loading the Tokenizer\n",
    "for this work we use the tokenizer from **`distilbert-base-cased`**. DistilBERT is a lighter but faster version of BERT that retains most of its performance. The `cased` version imposed the capitalization as a strong feature for Named Entity Recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a9ca5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')), '(Request ID: bec93c63-47d3-496a-b3b6-731c676972f4)')' thrown while requesting HEAD https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# load BERT's tokenizer -- this\n",
    "#\n",
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b794861",
   "metadata": {},
   "source": [
    "### 0.5 Token Alignment and Word IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4878054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here's an example showing how to tokenize texts and create the corresponding aligned and encoded labels\n",
    "#\n",
    "# Note that the tokenizer enables to retrieve the index of the corresponding wordform for each (sub-word) token\n",
    "# through the inputs.word_ids(batch_index=i) function (to retrieve input word indices for each token in \n",
    "# inputs['input_ids'][i]). Special tokens ([CLS], [SEP], [PAD]) are mapped to None. We will make use of this\n",
    "# mapping to create token-level labels adapted to sub-word tokenization. See next cell.\n",
    "#\n",
    "train_texts = [x['tokens'] for x in data['train']]\n",
    "train_labels = [x['tags'] for x in data['train']]\n",
    "\n",
    "inputs = tokenizer(train_texts, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(train_texts[0])\n",
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
    "print(inputs.word_ids(batch_index=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455340ba",
   "metadata": {},
   "source": [
    "Here the input labels are defined at the **word level**, but the model operates at the **sub-word level**. If the tokenizer splits the single word into multiple tokens, tje label list will be shorter than our token list, causing a mismatch during training.\n",
    "\n",
    "\n",
    "In order to sort thi out we use, the hugging face method called `word_ids()`. It returns a list mapping each token to its original word index Here, special tokens like `[CLS]` and `[SEP]` are mapped to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47e0d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spanish', 'Farm', 'Minister', 'Loyola', 'de', 'Palacio', 'had', 'earlier', 'accused', 'Fischler', 'at', 'an', 'EU', 'farm', 'ministers', \"'\", 'meeting', 'of', 'causing', 'unjustified', 'alarm', 'through', '\"', 'dangerous', 'generalisation', '.', '\"'] ['B-MISC', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "[CLS]  --  NONE\n",
      "Spanish  --  B-MISC\n",
      "Farm  --  O\n",
      "Minister  --  O\n",
      "Loyola  --  B-PER\n",
      "de  --  I-PER\n",
      "Pa  --  I-PER\n",
      "##la  --  I-PER\n",
      "##cio  --  I-PER\n",
      "had  --  O\n",
      "earlier  --  O\n",
      "accused  --  O\n",
      "Fi  --  B-PER\n",
      "##sch  --  I-PER\n",
      "##ler  --  I-PER\n",
      "at  --  O\n",
      "an  --  O\n",
      "EU  --  B-ORG\n",
      "farm  --  O\n",
      "ministers  --  O\n",
      "'  --  O\n",
      "meeting  --  O\n",
      "of  --  O\n",
      "causing  --  O\n",
      "un  --  O\n",
      "##ju  --  O\n",
      "##st  --  O\n",
      "##ified  --  O\n",
      "alarm  --  O\n",
      "through  --  O\n",
      "\"  --  O\n",
      "dangerous  --  O\n",
      "general  --  O\n",
      "##isation  --  O\n",
      ".  --  O\n",
      "\"  --  O\n",
      "[SEP]  --  NONE\n"
     ]
    }
   ],
   "source": [
    "def align_and_encode_labels(_token_ids, _word_ids, _labels):\n",
    "    '''\n",
    "    Align word-level labels to sub-word tokens for an entry\n",
    "    '''\n",
    "    \n",
    "    global tag2id\n",
    "    \n",
    "    ignore_id = -100\n",
    "    \n",
    "    buf = [ignore_id] # ignore tag for token [CLS]\n",
    "    \n",
    "    prev_token_word = -1\n",
    "    which_type = 0\n",
    "    \n",
    "    # print(len(_token_ids), tokenizer.convert_ids_to_tokens(_token_ids))\n",
    "    # print(_word_ids)\n",
    "    # print(_labels) \n",
    "    \n",
    "    for i in range(1, len(_token_ids)):\n",
    "        word_id = _word_ids[i]\n",
    "        \n",
    "        if word_id == None:\n",
    "            # token does not belong to any input word ([CLS], [SEP] or [PAD]) -- ignore\n",
    "            buf.append(ignore_id)\n",
    "            \n",
    "        else:\n",
    "            tag_id = tag2id[_labels[word_id]]\n",
    "\n",
    "            if word_id == prev_token_word: \n",
    "            # sub-word token of the previous word: need to do something\n",
    "            #   word has an O tag: just use a O tag\n",
    "            #   word has an I-X tag: just use the I-X tag\n",
    "            #   word has a B-X tag: replace by corresponding I-X tag\n",
    "                        \n",
    "                buf.append(tag_id + 1 if tag_id in (1, 3, 5, 7) else tag_id)\n",
    "        \n",
    "            else:\n",
    "                # token starting a new word --> keep tag unchanged\n",
    "                prev_token_word = word_id\n",
    "                buf.append(tag_id)\n",
    "    \n",
    "    return buf\n",
    "\n",
    "#\n",
    "# The following illustrate how we can get aligned and encoded labels for sample i in the training set.\n",
    "#\n",
    "\n",
    "i = 10\n",
    "\n",
    "print(train_texts[i], train_labels[i])\n",
    "\n",
    "new_labels = align_and_encode_labels(inputs['input_ids'][i], inputs.word_ids(batch_index=i), train_labels[i])\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][i])\n",
    "\n",
    "for j in range(len(tokens)):\n",
    "    if tokens[j] != '[PAD]':\n",
    "        print(tokens[j], ' -- ', id2tag[new_labels[j]] if new_labels[j] >= 0 else 'NONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f6f08b",
   "metadata": {},
   "source": [
    "The function `align_and_encode_labels` iterates through the BERT tokens and uses the `word_ids` map to assign the correct label ID. \n",
    "For each token in the BERT sequence:\n",
    "\n",
    "* **Special Tokens:** If the word ID is `None` (e.g., `[CLS]`, `[SEP]`, `[PAD]`), assign the label `-100`.\n",
    "* **New Words:** If the token marks the start of a new word, assign the original tag ID (e.g., `B-PER`).\n",
    "* **Sub-words:** If the token is a split part of the previous word (same word ID):\n",
    "* If the original tag was a Beginning tag (`B-X`), convert it to an Inside tag (`I-X`).\n",
    "* If the original tag was already Inside (`I-X`) or Outside (`O`), keep it unchanged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfeffdc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef1d71",
   "metadata": {},
   "source": [
    "## 1. Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db29cc",
   "metadata": {},
   "source": [
    "We cannot use the raw text directly to train LST RNN-based model/BERT-based models. We need to transform the input data into a format compatible with the model's tokenizer. The `NERDataset` (inherit from PyTorch `Dataset` class) were designed to address this and\n",
    "it handle two main challenges: **Sub-word Tokenization** and **Label Alignment**.\n",
    "\n",
    "The original CONLL-03 dataset provides text tokenized at the word level with one tag per word. However as mentioned earlier, transformer based models use sub-word tokenizers. A single word might be split into multiple tokens. For example, \"embedding\" might become `['em', '##bed', '##ding']`. In order to ensure that the labels align with these new tokens, We use the given helper function `align_and_encode_labels` (defined previously) with with the tokenizer's `word_ids()` method to map the original tags to the new sub-word sequence.\n",
    "\n",
    "**The `NERDataset` Class**\n",
    "We use the `distilbert-base-cased` tokenizer. `is_split_into_words=True` tells the tokenizer that the input is already split into words (not a raw string), preventing it from splitting the list further. The `padding=True` and `truncation=True` ensures all sequences in the batch have the same length (padding) and do not exceed the model's maximum limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, _data, _tokenizer):\n",
    "\n",
    "        # _data is the list of dictionaries [{'tokens': [...], 'tags': [...]}, ...]\n",
    "        self.raw_tokens = [x['tokens'] for x in _data] #words\n",
    "        self.raw_tags = [x['tags'] for x in _data]   #associated tags \n",
    "        \n",
    "        # Tokenize the sentences (sub-word tokenizer)\n",
    "        self.encodings = _tokenizer(\n",
    "            self.raw_tokens, \n",
    "            is_split_into_words=True, #let the tokenizer know thats sentence is already split\n",
    "            padding=True, #make all the sequence is same lenght\n",
    "            truncation=True,  # for long sentence (otherwise bert will crash)\n",
    "            return_tensors='pt' #return the o/p in Py-torch Tensor\n",
    "        )\n",
    "    \n",
    "        # Generate a list of label ids matching the new sub-word tokens\n",
    "        self.labels = []\n",
    "        for i in range(len(_data)):\n",
    "            # get the alignment info (word_ids) for this specific sample\n",
    "            word_ids = self.encodings.word_ids(batch_index=i)\n",
    "            token_ids = self.encodings['input_ids'][i] #get the token ids like [CLS], [SEP], [PAD]\n",
    "            \n",
    "    \n",
    "            # convert token_ids to list because the helper expects a list\n",
    "            aligned_label = align_and_encode_labels(token_ids.tolist(), word_ids, self.raw_tags[i])\n",
    "            \n",
    "            self.labels.append(aligned_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "#tok_fn =  lambda x: tokenizer(x, is_split_into_words=True, truncation=True, padding=True) #tokenization logic was moved into the class \n",
    "tok_fn = tokenizer  \n",
    "\n",
    "\n",
    "# Initialize datasets using the \"data\" dictionary\n",
    "ds = dict()\n",
    "ds['train'] = NERDataset(data['train'], tok_fn)\n",
    "ds['valid'] = NERDataset(data['valid'], tok_fn)\n",
    "ds['test'] = NERDataset(data['test'], tok_fn)\n",
    "\n",
    "# Create Pytorch DataLoaders \n",
    "# DataLoaders will create the traning batches for later models \n",
    "train_loader = DataLoader(ds['train'], batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(ds['valid'], batch_size=32)\n",
    "test_loader = DataLoader(ds['test'], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5cbd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single batch from the training loader\n",
    "batch = next(iter(train_loader)) #create iterator and take the very first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afab4e0",
   "metadata": {},
   "source": [
    "Before proceeding to modeling, lets inspect a single batch yielded by the `DataLoader`. Here, both the inputs and labels are expected to have the shape `(Batch_Size, Sequence_Length)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09e16e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([32, 173])\n",
      "Label Shape: torch.Size([32, 173])\n",
      "[CLS]           -100       IGNORE\n",
      "Tim             5          B-PER\n",
      "He              6          I-PER\n",
      "##n             6          I-PER\n",
      "##man           6          I-PER\n",
      "(               0          O\n",
      "Britain         1          B-LOC\n",
      ")               0          O\n",
      "beat            0          O\n",
      "Roberto         5          B-PER\n",
      "J               6          I-PER\n",
      "##aba           6          I-PER\n",
      "##li            6          I-PER\n",
      "(               0          O\n",
      "Brazil          1          B-LOC\n",
      ")               0          O\n",
      "6               0          O\n",
      "-               0          O\n",
      "2               0          O\n",
      "6               0          O\n",
      "-               0          O\n",
      "3               0          O\n",
      "6               0          O\n",
      "-               0          O\n",
      "4               0          O\n",
      "[SEP]           -100       IGNORE\n"
     ]
    }
   ],
   "source": [
    "# Both input_ids and labels have the shape of #(Batch_Size, Sequence_Length)\n",
    "print(f\"Input Shape: {batch['input_ids'].shape}\") \n",
    "print(f\"Label Shape: {batch['labels'].shape}\")\n",
    "\n",
    "\n",
    "# first sentence in this batch\n",
    "input_ids = batch['input_ids'][0]\n",
    "labels = batch['labels'][0]\n",
    "\n",
    "# Convert IDs back to words so we can read them\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "for token, label_id in zip(tokens, labels):\n",
    "    if token != '[PAD]': # non padding tokens for cleaner output\n",
    "        label_name = id2tag[label_id.item()] if label_id.item() != -100 else \"IGNORE\"\n",
    "        print(f\"{token:<15} {label_id.item():<10} {label_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30860c44",
   "metadata": {},
   "source": [
    "The decoded tokens and their corresponding label IDs verify that padding tokens are correctly ignored (`-100`) and entities are aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690283b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62f931",
   "metadata": {},
   "source": [
    "## 2. LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8705e1c",
   "metadata": {},
   "source": [
    "### 2.1 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cfe75",
   "metadata": {},
   "source": [
    "Our baseline model is a Recurrent Neural Network (RNN) using 2 Long Short-Term Memory (LSTM) units. This model consists of a *Embedding Layer:* which converts sparse token IDs into dense vectors of size `100`. The next step is a *Bi-Directional LSTM*. This layer Process the text in both directions (Left-to-Right and Right-to-Left) allows the model to capture context from both past and future tokens (which is crucial for NER).\n",
    "\n",
    "*  *Dropout:* Applied at `0.25` to prevent overfitting by randomly zeroing out elements of the input tensor (DL- Technique).\n",
    "*  *Linear Head:* A fully connected layer projects the LSTM hidden states to the `9` output classes (tags).\n",
    "*  The forward pass includes a specific permutation step at the end to match the dimensions before calculating the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f0d30572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTM_NER(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocsize, n_tags, embed_dim=200, hidden_dim=256, dropout=0.25):\n",
    "        super(LSTM_NER, self).__init__()\n",
    "\n",
    "        self.vocabulary_size = vocsize\n",
    "        self.nclasses = n_tags\n",
    "        \n",
    "        # Embedding Layer\n",
    "        self.embedding = torch.nn.Embedding(vocsize, embed_dim, padding_idx=0) #padding_idx=0 becuase BERT pad token id is 0)\n",
    "        \n",
    "        # LSTM Layer (Output dim = hidden_dim * 2)\n",
    "        self.rnn = torch.nn.LSTM(embed_dim, \n",
    "                                 hidden_dim, \n",
    "                                 batch_first=True, \n",
    "                                 bidirectional=True, # 2 hidden states per token (Left->Right & Right->Left)\n",
    "                                 dropout=dropout if dropout else 0)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = torch.nn.Dropout(dropout) if dropout else None\n",
    "        \n",
    "        # Linear Layer |  Input: hidden_dim * 2 , Output: n_tags \n",
    "        self.linear = torch.nn.Linear(hidden_dim * 2, n_tags)\n",
    "  \n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        x = self.embedding(input_ids)  # input_ids shape: [batch_size, seq_len]\n",
    "        \n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        # Data run via Bi-LSTM\n",
    "        x, _ = self.rnn(x) # x shape: (batch_size, seq_len, hidden_dim * 2) \n",
    "        \n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        # Data project to Tag probabilities\n",
    "        x = self.linear(x) # x shape: (batch_size, seq_len, n_tags)\n",
    "        \n",
    "        # Permute for Loss Function (swap dimensions 1 and 2)\n",
    "        return x.permute(0, 2, 1)  # because loss function wants batch_size * nclasses * maxlen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c11b3c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We initialize the model using the vocabulary size from the tokenizer (~29,000 tokens). We select a hidden dimension of 256, resulting in a 512-dimensional representation (256 forward + 256 backward) feeding into the final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "447cd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ensai/miniconda3/envs/torchgpu/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "INPUT_DIM = tokenizer.vocab_size  # ~29,000 (from BERT tokenizer)\n",
    "OUTPUT_DIM = len(tag2id)          # 9 tags (O, B-PER, etc.)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "DROPOUT = 0.35\n",
    "\n",
    "# Initialize Model\n",
    "lstm_model = LSTM_NER(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, DROPOUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391a2c3",
   "metadata": {},
   "source": [
    "### 2.2 Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d28b3",
   "metadata": {},
   "source": [
    "* **`train_step`**: Handles the forward pass, loss calculation, backpropagation, and optimizer updates for a single epoch (also prints running loss statistics to monitor convergence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2632217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(_model, _loader, _loss, _optim, device=\"cpu\", report=0):\n",
    "    '''\n",
    "    NER Training step.   \n",
    "    '''\n",
    "    _model.train(True)\n",
    "    total_loss = 0.\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, batch in enumerate(_loader):\n",
    "        _optim.zero_grad()\n",
    "\n",
    "        # CHANGE: Use 'labels' (plural) to match NERDataset\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # CHANGE: Filter out 'labels' to get inputs (input_ids, attention_mask)\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        \n",
    "        # Forward pass\n",
    "        # The LSTM_NER model we defined accepts **inputs (input_ids is required)\n",
    "        outputs = _model(**inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        # outputs shape: [Batch, Classes, Seq_Len] (due to permute in model)\n",
    "        # labels shape:  [Batch, Seq_Len]\n",
    "        # CrossEntropyLoss handles this automatically\n",
    "        loss = _loss(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        _optim.step()\n",
    "\n",
    "        if report != 0 and i % report == report - 1:\n",
    "            print('  batch {} avg. loss per batch={:.4f}'.format(i + 1, running_loss / report))\n",
    "            running_loss = 0.\n",
    "\n",
    "    _model.train(False)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6bb9e6",
   "metadata": {},
   "source": [
    "* **`eval_step`**: Performs inference on the validation set without computing gradients (`torch.no_grad()`). This will help to track the model's generalization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d0b12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(_model, _loader, _loss, device='cpu'):\n",
    "    '''\n",
    "    Evaluate the NER model's performance (Validation Loss).\n",
    "    '''\n",
    "    _model.eval()\n",
    "    total_loss = 0.\n",
    "\n",
    "    for batch in _loader:\n",
    "        # CHANGE: Use 'labels' (plural)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # CHANGE: Filter out 'labels'\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = _model(**inputs)\n",
    "            \n",
    "        # Calculate validation loss\n",
    "        loss = _loss(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Return average loss per batch\n",
    "    return total_loss / len(_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354aa1d",
   "metadata": {},
   "source": [
    "### 2.3 Training Setup\n",
    "\n",
    "\n",
    "* **Hyperparameters:** Learning rate of `1e-3` (standard for RNNs), a batch size of `32`, and train for `5` epochs.\n",
    "* **Optimizer:** The **Adam** optimizer, which generally converges faster than SGD for recurrent networks.\n",
    "* **Loss Function:** The `CrossEntropyLoss` becuase we set `ignore_index=-100`. This ensures that the loss function (and thus the gradient updates) effectively \"skips\" the padding tokens and the sub-word tokens that were masked during preprocessing.\n",
    "* **Device:** GPU (Fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc466adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#PARAMETERS\n",
    "lr = 1e-3           # 1e-3 is standard for LSTM \n",
    "nepochs = 5         # NER learns fast so nepch was set to 5 \n",
    "report_freq = 10    # Print stats every 10 batches\n",
    "batch_size = 32\n",
    "l2lambda = 2e-4 #to prevent overfitting\n",
    "\n",
    "#if torch.backends.mps.is_built(): \n",
    "#    device = \"mps\"\n",
    "#    torch.mps.empty_cache()\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f'Running on {device} device')\n",
    "\n",
    "\n",
    "\n",
    "lstm_model = lstm_model.to(device)\n",
    "\n",
    "\n",
    "#OPTIMIZER & LOSS\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=lr, weight_decay=l2lambda)\n",
    "celoss = torch.nn.CrossEntropyLoss(ignore_index=-100) #-100 tells PyTorch to ignore padding and sub-word parts (##ing)\n",
    "\n",
    "\n",
    "loader = dict()\n",
    "loader['train'] = DataLoader(ds['train'], batch_size=batch_size, shuffle=True)\n",
    "loader['valid'] = DataLoader(ds['valid'], batch_size=batch_size)\n",
    "loader['test']  = DataLoader(ds['test'],  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f406fa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"864pt\" height=\"353pt\"\n",
       " viewBox=\"0.00 0.00 864.00 353.39\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.66 0.66) rotate(0) translate(4 531)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-531 1304,-531 1304,4 -4,4\"/>\n",
       "<!-- 137424975467120 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>137424975467120</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"658,-31 575,-31 575,0 658,0 658,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 9, 10)</text>\n",
       "</g>\n",
       "<!-- 137424947940272 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>137424947940272</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"620,-92 507,-92 507,-73 620,-73 620,-92\"/>\n",
       "<text text-anchor=\"middle\" x=\"563.5\" y=\"-80\" font-family=\"monospace\" font-size=\"10.00\">PermuteBackward0</text>\n",
       "</g>\n",
       "<!-- 137424947940272&#45;&gt;137424975467120 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>137424947940272&#45;&gt;137424975467120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570.65,-72.73C577.65,-64.15 588.62,-50.69 598.07,-39.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"601,-41.05 604.61,-31.08 595.58,-36.62 601,-41.05\"/>\n",
       "</g>\n",
       "<!-- 137424947944208 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>137424947944208</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"626,-153 531,-153 531,-134 626,-134 626,-153\"/>\n",
       "<text text-anchor=\"middle\" x=\"578.5\" y=\"-141\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 137424947944208&#45;&gt;137424947940272 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>137424947944208&#45;&gt;137424947940272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M576.29,-133.79C574.18,-125.52 570.95,-112.79 568.26,-102.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"571.58,-101.07 565.72,-92.24 564.79,-102.8 571.58,-101.07\"/>\n",
       "</g>\n",
       "<!-- 137424947943824 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>137424947943824</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"667,-208 566,-208 566,-189 667,-189 667,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-196\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 137424947943824&#45;&gt;137424947944208 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>137424947943824&#45;&gt;137424947944208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M610.23,-188.75C604.91,-181.34 597.14,-170.5 590.62,-161.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"593.33,-159.18 584.66,-153.09 587.64,-163.26 593.33,-159.18\"/>\n",
       "</g>\n",
       "<!-- 137426882088704 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>137426882088704</title>\n",
       "<polygon fill=\"#a2cd5a\" stroke=\"black\" points=\"703,-98 638,-98 638,-67 703,-67 703,-98\"/>\n",
       "<text text-anchor=\"middle\" x=\"670.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\"> (10, 9)</text>\n",
       "</g>\n",
       "<!-- 137424947943824&#45;&gt;137426882088704 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>137424947943824&#45;&gt;137426882088704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M620.56,-188.93C628.66,-171.83 647.08,-132.94 659.14,-107.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"662.45,-108.66 663.57,-98.13 656.13,-105.67 662.45,-108.66\"/>\n",
       "</g>\n",
       "<!-- 137424947944352 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>137424947944352</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"550,-263 449,-263 449,-244 550,-244 550,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"499.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947944352&#45;&gt;137424947943824 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>137424947944352&#45;&gt;137424947943824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M518.3,-243.98C537.12,-235.46 566.32,-222.23 588,-212.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"589.7,-215.48 597.36,-208.17 586.81,-209.11 589.7,-215.48\"/>\n",
       "</g>\n",
       "<!-- 137424978593744 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>137424978593744</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"539,-329 456,-329 456,-299 539,-299 539,-329\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-317\" font-family=\"monospace\" font-size=\"10.00\">linear.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\"> (9)</text>\n",
       "</g>\n",
       "<!-- 137424978593744&#45;&gt;137424947944352 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>137424978593744&#45;&gt;137424947944352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.98,-298.84C498.24,-291.21 498.57,-281.7 498.85,-273.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"502.36,-273.38 499.2,-263.27 495.36,-273.14 502.36,-273.38\"/>\n",
       "</g>\n",
       "<!-- 137424947953232 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>137424947953232</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"664,-263 569,-263 569,-244 664,-244 664,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 137424947953232&#45;&gt;137424947943824 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>137424947953232&#45;&gt;137424947943824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M616.5,-243.75C616.5,-236.8 616.5,-226.85 616.5,-218.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"620,-218.09 616.5,-208.09 613,-218.09 620,-218.09\"/>\n",
       "</g>\n",
       "<!-- 137438017097488 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>137438017097488</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"676,-323.5 557,-323.5 557,-304.5 676,-304.5 676,-323.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-311.5\" font-family=\"monospace\" font-size=\"10.00\">CudnnRnnBackward0</text>\n",
       "</g>\n",
       "<!-- 137438017097488&#45;&gt;137424947953232 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>137438017097488&#45;&gt;137424947953232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M616.5,-304.37C616.5,-296.25 616.5,-283.81 616.5,-273.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"620,-273.17 616.5,-263.17 613,-273.17 620,-273.17\"/>\n",
       "</g>\n",
       "<!-- 137424947939456 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>137424947939456</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"125,-389.5 0,-389.5 0,-370.5 125,-370.5 125,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">EmbeddingBackward0</text>\n",
       "</g>\n",
       "<!-- 137424947939456&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>137424947939456&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.48,-370.49C114.19,-368.48 125.75,-366.48 136.5,-365 318.14,-339.93 366.03,-355.27 547.5,-329 554.25,-328.02 561.33,-326.81 568.28,-325.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"569.17,-328.9 578.31,-323.55 567.83,-322.03 569.17,-328.9\"/>\n",
       "</g>\n",
       "<!-- 137424947940032 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>137424947940032</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"108,-455.5 7,-455.5 7,-436.5 108,-436.5 108,-455.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-443.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947940032&#45;&gt;137424947939456 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>137424947940032&#45;&gt;137424947939456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.17,-436.37C58.9,-427.07 60.08,-411.98 61.02,-399.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"64.51,-400.15 61.8,-389.91 57.54,-399.6 64.51,-400.15\"/>\n",
       "</g>\n",
       "<!-- 137424933978272 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>137424933978272</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"114,-527 1,-527 1,-497 114,-497 114,-527\"/>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-515\" font-family=\"monospace\" font-size=\"10.00\">embedding.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-504\" font-family=\"monospace\" font-size=\"10.00\"> (28996, 100)</text>\n",
       "</g>\n",
       "<!-- 137424933978272&#45;&gt;137424947940032 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>137424933978272&#45;&gt;137424947940032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.5,-496.8C57.5,-487.7 57.5,-475.79 57.5,-465.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61,-465.84 57.5,-455.84 54,-465.84 61,-465.84\"/>\n",
       "</g>\n",
       "<!-- 137424947945168 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>137424947945168</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"247,-389.5 146,-389.5 146,-370.5 247,-370.5 247,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947945168&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>137424947945168&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.32,-370.45C238.83,-368.48 247.97,-366.52 256.5,-365 384.8,-342.16 418.88,-349.97 547.5,-329 553.83,-327.97 560.47,-326.77 567.02,-325.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"568.05,-328.88 577.19,-323.52 566.7,-322.01 568.05,-328.88\"/>\n",
       "</g>\n",
       "<!-- 137425676854096 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>137425676854096</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"239,-461 126,-461 126,-431 239,-431 239,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_ih_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"182.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 100)</text>\n",
       "</g>\n",
       "<!-- 137425676854096&#45;&gt;137424947945168 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>137425676854096&#45;&gt;137424947945168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.61,-430.8C187.6,-421.7 190.2,-409.79 192.37,-399.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.85,-400.36 194.57,-389.84 189.01,-398.87 195.85,-400.36\"/>\n",
       "</g>\n",
       "<!-- 137424947948144 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>137424947948144</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"367,-389.5 266,-389.5 266,-370.5 367,-370.5 367,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"316.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947948144&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>137424947948144&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.86,-370.47C361.97,-368.64 370.52,-366.74 378.5,-365 442.63,-351.03 516.63,-335.59 564.87,-325.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"565.67,-329.02 574.76,-323.57 564.26,-322.17 565.67,-329.02\"/>\n",
       "</g>\n",
       "<!-- 137424933993152 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>137424933993152</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"370,-461 257,-461 257,-431 370,-431 370,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_hh_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"313.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 256)</text>\n",
       "</g>\n",
       "<!-- 137424933993152&#45;&gt;137424947948144 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>137424933993152&#45;&gt;137424947948144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.17,-430.8C314.59,-421.7 315.15,-409.79 315.61,-399.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"319.11,-400 316.09,-389.84 312.12,-399.67 319.11,-400\"/>\n",
       "</g>\n",
       "<!-- 137424947947472 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>137424947947472</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"489,-389.5 388,-389.5 388,-370.5 489,-370.5 489,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947947472&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>137424947947472&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462.51,-370.37C493.51,-359.22 547.66,-339.75 582.79,-327.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"584.36,-330.27 592.59,-323.6 582,-323.69 584.36,-330.27\"/>\n",
       "</g>\n",
       "<!-- 137426881624608 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>137426881624608</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"489,-461 388,-461 388,-431 489,-431 489,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_ih_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"438.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 137426881624608&#45;&gt;137424947947472 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>137426881624608&#45;&gt;137424947947472</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M438.5,-430.8C438.5,-421.7 438.5,-409.79 438.5,-399.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"442,-399.84 438.5,-389.84 435,-399.84 442,-399.84\"/>\n",
       "</g>\n",
       "<!-- 137424947941280 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>137424947941280</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"608,-389.5 507,-389.5 507,-370.5 608,-370.5 608,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947941280&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>137424947941280&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M565.46,-370.37C574.64,-360.4 589.96,-343.79 601.42,-331.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"604.09,-333.63 608.29,-323.91 598.94,-328.89 604.09,-333.63\"/>\n",
       "</g>\n",
       "<!-- 137426881625808 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>137426881625808</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"608,-461 507,-461 507,-431 608,-431 608,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_hh_l0</text>\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 137426881625808&#45;&gt;137424947941280 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>137426881625808&#45;&gt;137424947941280</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M557.5,-430.8C557.5,-421.7 557.5,-409.79 557.5,-399.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"561,-399.84 557.5,-389.84 554,-399.84 561,-399.84\"/>\n",
       "</g>\n",
       "<!-- 137424947937440 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>137424947937440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"727,-389.5 626,-389.5 626,-370.5 727,-370.5 727,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"676.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947937440&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>137424947937440&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M668.41,-370.37C659.07,-360.4 643.49,-343.79 631.84,-331.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"634.24,-328.81 624.85,-323.91 629.13,-333.59 634.24,-328.81\"/>\n",
       "</g>\n",
       "<!-- 137426881620768 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>137426881620768</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"787,-461 626,-461 626,-431 787,-431 787,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"706.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_ih_l0_reverse</text>\n",
       "<text text-anchor=\"middle\" x=\"706.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 100)</text>\n",
       "</g>\n",
       "<!-- 137426881620768&#45;&gt;137424947937440 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>137426881620768&#45;&gt;137424947937440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M699.84,-430.8C695.44,-421.41 689.63,-409.02 684.91,-398.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"688.06,-397.41 680.65,-389.84 681.72,-400.38 688.06,-397.41\"/>\n",
       "</g>\n",
       "<!-- 137424947943200 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>137424947943200</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"846,-389.5 745,-389.5 745,-370.5 846,-370.5 846,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"795.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947943200&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>137424947943200&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M771.36,-370.37C740.18,-359.22 685.73,-339.75 650.4,-327.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"651.14,-323.67 640.54,-323.6 648.78,-330.26 651.14,-323.67\"/>\n",
       "</g>\n",
       "<!-- 137424975680192 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>137424975680192</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"966,-461 805,-461 805,-431 966,-431 966,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"885.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.weight_hh_l0_reverse</text>\n",
       "<text text-anchor=\"middle\" x=\"885.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 256)</text>\n",
       "</g>\n",
       "<!-- 137424975680192&#45;&gt;137424947943200 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>137424975680192&#45;&gt;137424947943200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M865.53,-430.8C850.86,-420.37 830.99,-406.24 816.16,-395.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"817.85,-392.6 807.68,-389.66 813.8,-398.31 817.85,-392.6\"/>\n",
       "</g>\n",
       "<!-- 137424947950496 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>137424947950496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"965,-389.5 864,-389.5 864,-370.5 965,-370.5 965,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"914.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947950496&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>137424947950496&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M878.36,-370.43C870.5,-368.61 862.23,-366.71 854.5,-365 790.62,-350.84 716.86,-335.5 668.59,-325.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"669.19,-322.15 658.69,-323.57 667.79,-329.01 669.19,-322.15\"/>\n",
       "</g>\n",
       "<!-- 137424975689312 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>137424975689312</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1133,-461 984,-461 984,-431 1133,-431 1133,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"1058.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_ih_l0_reverse</text>\n",
       "<text text-anchor=\"middle\" x=\"1058.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 137424975689312&#45;&gt;137424947950496 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>137424975689312&#45;&gt;137424947950496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1026.9,-430.95C1001.87,-419.83 967.2,-404.42 943.01,-393.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"944.22,-390.38 933.66,-389.52 941.38,-396.78 944.22,-390.38\"/>\n",
       "</g>\n",
       "<!-- 137424947939072 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>137424947939072</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1084,-389.5 983,-389.5 983,-370.5 1084,-370.5 1084,-389.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1033.5\" y=\"-377.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137424947939072&#45;&gt;137438017097488 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>137424947939072&#45;&gt;137438017097488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M999.92,-370.45C991.64,-368.51 982.78,-366.56 974.5,-365 875.01,-346.29 758.75,-331.31 686.36,-322.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"686.35,-319.26 676.01,-321.57 685.53,-326.21 686.35,-319.26\"/>\n",
       "</g>\n",
       "<!-- 137424975689072 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>137424975689072</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1300,-461 1151,-461 1151,-431 1300,-431 1300,-461\"/>\n",
       "<text text-anchor=\"middle\" x=\"1225.5\" y=\"-449\" font-family=\"monospace\" font-size=\"10.00\">rnn.bias_hh_l0_reverse</text>\n",
       "<text text-anchor=\"middle\" x=\"1225.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 137424975689072&#45;&gt;137424947939072 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>137424975689072&#45;&gt;137424947939072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1183.36,-430.95C1148.95,-419.48 1100.88,-403.46 1068.55,-392.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1069.65,-389.36 1059.05,-389.52 1067.43,-396 1069.65,-389.36\"/>\n",
       "</g>\n",
       "<!-- 137424947942816 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>137424947942816</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"887,-263 810,-263 810,-244 887,-244 887,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"848.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 137424947942816&#45;&gt;137424947943824 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>137424947942816&#45;&gt;137424947943824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M811.23,-243.98C771.18,-234.84 707.43,-220.27 663.86,-210.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"664.6,-206.9 654.07,-208.08 663.04,-213.72 664.6,-206.9\"/>\n",
       "</g>\n",
       "<!-- 137430937604720 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>137430937604720</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1027,-323.5 926,-323.5 926,-304.5 1027,-304.5 1027,-323.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"976.5\" y=\"-311.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 137430937604720&#45;&gt;137424947942816 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>137430937604720&#45;&gt;137424947942816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M957.89,-304.49C936.46,-294.7 901.06,-278.52 876.35,-267.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"877.68,-263.99 867.13,-263.02 874.78,-270.36 877.68,-263.99\"/>\n",
       "</g>\n",
       "<!-- 137424978607264 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>137424978607264</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1197,-395 1102,-395 1102,-365 1197,-365 1197,-395\"/>\n",
       "<text text-anchor=\"middle\" x=\"1149.5\" y=\"-383\" font-family=\"monospace\" font-size=\"10.00\">linear.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1149.5\" y=\"-372\" font-family=\"monospace\" font-size=\"10.00\"> (9, 512)</text>\n",
       "</g>\n",
       "<!-- 137424978607264&#45;&gt;137430937604720 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>137424978607264&#45;&gt;137430937604720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1111.53,-364.95C1080.93,-353.63 1038.33,-337.88 1009.22,-327.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1010.12,-323.7 999.52,-323.52 1007.69,-330.27 1010.12,-323.7\"/>\n",
       "</g>\n",
       "<!-- 137426882088704&#45;&gt;137424975467120 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>137426882088704&#45;&gt;137424975467120</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M658.25,-66.75C651.41,-58.52 642.76,-48.11 635.1,-38.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"637.79,-36.65 628.7,-31.19 632.4,-41.12 637.79,-36.65\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7cfc8cdbb130>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "dummy_input = torch.randint(\n",
    "    0, tokenizer.vocab_size, (1, 10)\n",
    ").to(device)\n",
    "output = lstm_model(dummy_input)\n",
    "# This traces how data flows from input -> embedding -> lstm -> linear\n",
    "make_dot(output, params=dict(lstm_model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30030912",
   "metadata": {},
   "source": [
    "### 2.4 Training Setup\n",
    "\n",
    "For 5 epochs\n",
    "\n",
    "* The average **Training Loss** and **Validation Loss** for each epoch were recorded (plotted).\n",
    "* A well behaving model should show both curves decreasing. (If the Validation Loss starts increasing while Training Loss decreases, it indicates **overfitting**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d294b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING TRAINING ---\n",
      "  batch 10 avg. loss per batch=0.1308\n",
      "  batch 20 avg. loss per batch=0.1620\n",
      "  batch 30 avg. loss per batch=0.1344\n",
      "  batch 40 avg. loss per batch=0.1652\n",
      "  batch 50 avg. loss per batch=0.1557\n",
      "  batch 60 avg. loss per batch=0.1603\n",
      "  batch 70 avg. loss per batch=0.1501\n",
      "  batch 80 avg. loss per batch=0.1585\n",
      "  batch 90 avg. loss per batch=0.1944\n",
      "  batch 100 avg. loss per batch=0.1695\n",
      "  batch 110 avg. loss per batch=0.1930\n",
      "  batch 120 avg. loss per batch=0.1862\n",
      "  batch 130 avg. loss per batch=0.1476\n",
      "  batch 140 avg. loss per batch=0.1694\n",
      "  batch 150 avg. loss per batch=0.1778\n",
      "  batch 160 avg. loss per batch=0.1747\n",
      "  batch 170 avg. loss per batch=0.2242\n",
      "  batch 180 avg. loss per batch=0.1920\n",
      "  batch 190 avg. loss per batch=0.1966\n",
      "  batch 200 avg. loss per batch=0.1731\n",
      "  batch 210 avg. loss per batch=0.1572\n",
      "  batch 220 avg. loss per batch=0.2077\n",
      "  batch 230 avg. loss per batch=0.1835\n",
      "  batch 240 avg. loss per batch=0.1730\n",
      "  batch 250 avg. loss per batch=0.1805\n",
      "  batch 260 avg. loss per batch=0.1749\n",
      "  batch 270 avg. loss per batch=0.2092\n",
      "  batch 280 avg. loss per batch=0.1961\n",
      "  batch 290 avg. loss per batch=0.1733\n",
      "  batch 300 avg. loss per batch=0.2091\n",
      "  batch 310 avg. loss per batch=0.1988\n",
      "  batch 320 avg. loss per batch=0.1767\n",
      "  batch 330 avg. loss per batch=0.2120\n",
      "  batch 340 avg. loss per batch=0.1965\n",
      "  batch 350 avg. loss per batch=0.1888\n",
      "  batch 360 avg. loss per batch=0.1754\n",
      "  batch 370 avg. loss per batch=0.1923\n",
      "  batch 380 avg. loss per batch=0.1860\n",
      "  batch 390 avg. loss per batch=0.1912\n",
      "  batch 400 avg. loss per batch=0.1829\n",
      "  batch 410 avg. loss per batch=0.2218\n",
      "  batch 420 avg. loss per batch=0.1815\n",
      "  batch 430 avg. loss per batch=0.2122\n",
      "  batch 10 avg. loss per batch=0.1703\n",
      "  batch 20 avg. loss per batch=0.1762\n",
      "  batch 30 avg. loss per batch=0.1784\n",
      "  batch 40 avg. loss per batch=0.1775\n",
      "  batch 50 avg. loss per batch=0.1401\n",
      "  batch 60 avg. loss per batch=0.1461\n",
      "  batch 70 avg. loss per batch=0.1619\n",
      "  batch 80 avg. loss per batch=0.1631\n",
      "  batch 90 avg. loss per batch=0.1581\n",
      "  batch 100 avg. loss per batch=0.1838\n",
      "  batch 110 avg. loss per batch=0.1678\n",
      "  batch 120 avg. loss per batch=0.1677\n",
      "  batch 130 avg. loss per batch=0.1661\n",
      "  batch 140 avg. loss per batch=0.1676\n",
      "  batch 150 avg. loss per batch=0.1463\n",
      "  batch 160 avg. loss per batch=0.1783\n",
      "  batch 170 avg. loss per batch=0.1490\n",
      "  batch 180 avg. loss per batch=0.1445\n",
      "  batch 190 avg. loss per batch=0.1585\n",
      "  batch 200 avg. loss per batch=0.2180\n",
      "  batch 210 avg. loss per batch=0.1964\n",
      "  batch 220 avg. loss per batch=0.1945\n",
      "  batch 230 avg. loss per batch=0.1846\n",
      "  batch 240 avg. loss per batch=0.1730\n",
      "  batch 250 avg. loss per batch=0.1754\n",
      "  batch 260 avg. loss per batch=0.1862\n",
      "  batch 270 avg. loss per batch=0.1657\n",
      "  batch 280 avg. loss per batch=0.1636\n",
      "  batch 290 avg. loss per batch=0.1744\n",
      "  batch 300 avg. loss per batch=0.1507\n",
      "  batch 310 avg. loss per batch=0.1857\n",
      "  batch 320 avg. loss per batch=0.1690\n",
      "  batch 330 avg. loss per batch=0.2148\n",
      "  batch 340 avg. loss per batch=0.1797\n",
      "  batch 350 avg. loss per batch=0.1845\n",
      "  batch 360 avg. loss per batch=0.1800\n",
      "  batch 370 avg. loss per batch=0.1897\n",
      "  batch 380 avg. loss per batch=0.1741\n",
      "  batch 390 avg. loss per batch=0.2055\n",
      "  batch 400 avg. loss per batch=0.1545\n",
      "  batch 410 avg. loss per batch=0.1934\n",
      "  batch 420 avg. loss per batch=0.1530\n",
      "  batch 430 avg. loss per batch=0.1568\n",
      "  batch 10 avg. loss per batch=0.1598\n",
      "  batch 20 avg. loss per batch=0.1523\n",
      "  batch 30 avg. loss per batch=0.1391\n",
      "  batch 40 avg. loss per batch=0.1393\n",
      "  batch 50 avg. loss per batch=0.1347\n",
      "  batch 60 avg. loss per batch=0.1478\n",
      "  batch 70 avg. loss per batch=0.1719\n",
      "  batch 80 avg. loss per batch=0.1620\n",
      "  batch 90 avg. loss per batch=0.1591\n",
      "  batch 100 avg. loss per batch=0.1520\n",
      "  batch 110 avg. loss per batch=0.1536\n",
      "  batch 120 avg. loss per batch=0.1425\n",
      "  batch 130 avg. loss per batch=0.1553\n",
      "  batch 140 avg. loss per batch=0.1674\n",
      "  batch 150 avg. loss per batch=0.1429\n",
      "  batch 160 avg. loss per batch=0.1574\n",
      "  batch 170 avg. loss per batch=0.1632\n",
      "  batch 180 avg. loss per batch=0.1623\n",
      "  batch 190 avg. loss per batch=0.1352\n",
      "  batch 200 avg. loss per batch=0.1750\n",
      "  batch 210 avg. loss per batch=0.1426\n",
      "  batch 220 avg. loss per batch=0.1475\n",
      "  batch 230 avg. loss per batch=0.1426\n",
      "  batch 240 avg. loss per batch=0.1601\n",
      "  batch 250 avg. loss per batch=0.1781\n",
      "  batch 260 avg. loss per batch=0.1549\n",
      "  batch 270 avg. loss per batch=0.1858\n",
      "  batch 280 avg. loss per batch=0.1422\n",
      "  batch 290 avg. loss per batch=0.1396\n",
      "  batch 300 avg. loss per batch=0.1725\n",
      "  batch 310 avg. loss per batch=0.1511\n",
      "  batch 320 avg. loss per batch=0.1759\n",
      "  batch 330 avg. loss per batch=0.1584\n",
      "  batch 340 avg. loss per batch=0.1606\n",
      "  batch 350 avg. loss per batch=0.1322\n",
      "  batch 360 avg. loss per batch=0.1633\n",
      "  batch 370 avg. loss per batch=0.1403\n",
      "  batch 380 avg. loss per batch=0.1546\n",
      "  batch 390 avg. loss per batch=0.1486\n",
      "  batch 400 avg. loss per batch=0.1427\n",
      "  batch 410 avg. loss per batch=0.1482\n",
      "  batch 420 avg. loss per batch=0.1488\n",
      "  batch 430 avg. loss per batch=0.1698\n",
      "  batch 10 avg. loss per batch=0.1511\n",
      "  batch 20 avg. loss per batch=0.1139\n",
      "  batch 30 avg. loss per batch=0.0999\n",
      "  batch 40 avg. loss per batch=0.1084\n",
      "  batch 50 avg. loss per batch=0.1428\n",
      "  batch 60 avg. loss per batch=0.1460\n",
      "  batch 70 avg. loss per batch=0.1527\n",
      "  batch 80 avg. loss per batch=0.1288\n",
      "  batch 90 avg. loss per batch=0.1277\n",
      "  batch 100 avg. loss per batch=0.1386\n",
      "  batch 110 avg. loss per batch=0.1412\n",
      "  batch 120 avg. loss per batch=0.1413\n",
      "  batch 130 avg. loss per batch=0.1480\n",
      "  batch 140 avg. loss per batch=0.1471\n",
      "  batch 150 avg. loss per batch=0.1549\n",
      "  batch 160 avg. loss per batch=0.1438\n",
      "  batch 170 avg. loss per batch=0.1446\n",
      "  batch 180 avg. loss per batch=0.1184\n",
      "  batch 190 avg. loss per batch=0.1482\n",
      "  batch 200 avg. loss per batch=0.1483\n",
      "  batch 210 avg. loss per batch=0.1748\n",
      "  batch 220 avg. loss per batch=0.1613\n",
      "  batch 230 avg. loss per batch=0.1322\n",
      "  batch 240 avg. loss per batch=0.1771\n",
      "  batch 250 avg. loss per batch=0.1549\n",
      "  batch 260 avg. loss per batch=0.1090\n",
      "  batch 270 avg. loss per batch=0.1769\n",
      "  batch 280 avg. loss per batch=0.1584\n",
      "  batch 290 avg. loss per batch=0.1583\n",
      "  batch 300 avg. loss per batch=0.1596\n",
      "  batch 310 avg. loss per batch=0.1675\n",
      "  batch 320 avg. loss per batch=0.1412\n",
      "  batch 330 avg. loss per batch=0.1477\n",
      "  batch 340 avg. loss per batch=0.1569\n",
      "  batch 350 avg. loss per batch=0.1842\n",
      "  batch 360 avg. loss per batch=0.1504\n",
      "  batch 370 avg. loss per batch=0.1873\n",
      "  batch 380 avg. loss per batch=0.1502\n",
      "  batch 390 avg. loss per batch=0.1714\n",
      "  batch 400 avg. loss per batch=0.1365\n",
      "  batch 410 avg. loss per batch=0.1250\n",
      "  batch 420 avg. loss per batch=0.1244\n",
      "  batch 430 avg. loss per batch=0.1379\n",
      "  batch 10 avg. loss per batch=0.1048\n",
      "  batch 20 avg. loss per batch=0.1238\n",
      "  batch 30 avg. loss per batch=0.1216\n",
      "  batch 40 avg. loss per batch=0.1253\n",
      "  batch 50 avg. loss per batch=0.1171\n",
      "  batch 60 avg. loss per batch=0.1206\n",
      "  batch 70 avg. loss per batch=0.1109\n",
      "  batch 80 avg. loss per batch=0.1177\n",
      "  batch 90 avg. loss per batch=0.0999\n",
      "  batch 100 avg. loss per batch=0.1029\n",
      "  batch 110 avg. loss per batch=0.1571\n",
      "  batch 120 avg. loss per batch=0.1284\n",
      "  batch 130 avg. loss per batch=0.1125\n",
      "  batch 140 avg. loss per batch=0.1204\n",
      "  batch 150 avg. loss per batch=0.1045\n",
      "  batch 160 avg. loss per batch=0.1377\n",
      "  batch 170 avg. loss per batch=0.1470\n",
      "  batch 180 avg. loss per batch=0.1269\n",
      "  batch 190 avg. loss per batch=0.1435\n",
      "  batch 200 avg. loss per batch=0.1477\n",
      "  batch 210 avg. loss per batch=0.1201\n",
      "  batch 220 avg. loss per batch=0.1414\n",
      "  batch 230 avg. loss per batch=0.1203\n",
      "  batch 240 avg. loss per batch=0.1406\n",
      "  batch 250 avg. loss per batch=0.1170\n",
      "  batch 260 avg. loss per batch=0.1466\n",
      "  batch 270 avg. loss per batch=0.1467\n",
      "  batch 280 avg. loss per batch=0.1482\n",
      "  batch 290 avg. loss per batch=0.1920\n",
      "  batch 300 avg. loss per batch=0.1303\n",
      "  batch 310 avg. loss per batch=0.1358\n",
      "  batch 320 avg. loss per batch=0.1392\n",
      "  batch 330 avg. loss per batch=0.1150\n",
      "  batch 340 avg. loss per batch=0.1230\n",
      "  batch 350 avg. loss per batch=0.1493\n",
      "  batch 360 avg. loss per batch=0.1262\n",
      "  batch 370 avg. loss per batch=0.1619\n",
      "  batch 380 avg. loss per batch=0.2001\n",
      "  batch 390 avg. loss per batch=0.1430\n",
      "  batch 400 avg. loss per batch=0.1293\n",
      "  batch 410 avg. loss per batch=0.1571\n",
      "  batch 420 avg. loss per batch=0.1325\n",
      "  batch 430 avg. loss per batch=0.1294\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "print(\"--- STARTING TRAINING ---\")\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    # train\n",
    "    total_train_loss = train_step(lstm_model, loader['train'], celoss, optimizer, device=device, report=report_freq)\n",
    "    avg_train_loss = total_train_loss / len(loader['train'])\n",
    "    \n",
    "    # -validate--\n",
    "    avg_valid_loss = eval_step(lstm_model, loader['valid'], celoss, device=device)\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    valid_losses.append(avg_valid_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "plt.figure(figsize=(6, 5.5))\n",
    "\n",
    "# training Loss (Blue)\n",
    "plt.plot(train_losses, label='Training Loss', marker='o', color='blue')\n",
    "\n",
    "# validation Loss (Red)\n",
    "plt.plot(valid_losses, label='Validation Loss', marker='x', color='red', linestyle='--')\n",
    "\n",
    "plt.title('Training vs Validation Loss (LSTM)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885b74c",
   "metadata": {},
   "source": [
    "**Observations:** Both the *Training Loss (Blue)* and *Validation Loss (Red)* are decreasing in parallel.\n",
    "\n",
    "**Conclusion:**\n",
    "The addition of weight decay ($2e-4$) successfully penalized the model's complexity, forcing it to learn more robust, generalizable features instead of memorizing the training noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c430cb",
   "metadata": {},
   "source": [
    "### 2.5 Save the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f54c6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_checkpoints'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4888cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename\n",
    "save_path = f'{output_dir}/lstm_ner_model.pt'\n",
    "\n",
    "#save the model's state_dict (the weights)\n",
    "torch.save(lstm_model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b623393",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396141b",
   "metadata": {},
   "source": [
    "## 3. BERT Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae63d8d",
   "metadata": {},
   "source": [
    "### 3.1 Architecture\n",
    "\n",
    "The difference between this model and the LSTM is how context is handled. The LSTM builds context sequentially (left-to-right and right-to-left). BERT uses Self Attention to look at the entire sentence at once. This results in Contextual Embeddings, where the vector for the word \"Bank\" in \"River Bank\" is mathematically different from the vector for \"Bank\" in \"Bank of America\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f78c4",
   "metadata": {},
   "source": [
    "**The `BERT_NER` Class** Has two parts: \n",
    "\n",
    "1. *The Encoder (`self.bert`):* The `distilbert-base-cased` were used. This model has already been trained on a massive corpus to understand English syntax and semantics. We use the `cased` version because capitalization is a strong signal for Named Entities (e.g., \"apple\" vs \"Apple\").\n",
    "\n",
    "2. *The Classification Head:* In document classification of llm-finetunning notebook, we take the `[CLS]` token (the first token) to represent the whole sentence. However, here we need a prediction for every token. Therefore, we take the `last_hidden_state` (the entire sequence of vectors) and pass it through a Linear layer.\n",
    "\n",
    "* *Input Dimension:* 768 (DistilBERT's hidden size)\n",
    "* *Output Dimension:* 9 (Number of tags)\n",
    "\n",
    "Unlike the LSTM, BERT explicitly requires an `attention_mask`. Since BERT processes the whole sequence simultaneously, the mask is critical to ensure the self attention mechanism does not \"attend\" to the padding tokens, which would otherwise distort the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346638f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERT_NER(nn.Module):\n",
    "    def __init__(self, checkpoint, num_tags, dropout=0.1):\n",
    "        super(BERT_NER, self).__init__()\n",
    "        \n",
    "        # Load the pre trained encoder (distilbert-base-cased)\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint) #AutoModel gets the raw hidden states (not pretrained head)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Classification head projects from hidden size  to number of tags\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_tags)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "\n",
    "        # pass inputs through the BERT encoder\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get the sequence of hidden states (batch_size, seq_len, hidden_size)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        \n",
    "        # Apply dropout for regularization\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        \n",
    "        # project to tag space: (batch_size, seq_len, num_tags)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f89575",
   "metadata": {},
   "source": [
    "### 3.2 Training and Evaluation and Run\n",
    "\n",
    "1.  *Optimizer (AdamW):* The AdamW (Adam with Weight Decay fixed) was used becuase it is the standard optimizer for Transformers.\n",
    "2.  *Learning Rate ($5e-5$):* We use a significantly lower learning rate compared to the LSTM ($1e-3$). Since we are *fine-tuning* a pre-trained model we need a low training rate (a high learning rate would destroy the prelearned weights).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Model and Device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "bert_model = BERT_NER(checkpoint, num_tags=len(tag2id)).to(device)\n",
    "\n",
    "# Optimizer and Loss\n",
    "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "# training Function\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        #move whole batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass: (batch_size, seq_len, num_tags)\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Flatten outputs and labels for CrossEntropyLoss\n",
    "        # Active logits: (batch_size * seq_len, num_tags)\n",
    "        # Active labels: (batch_size * seq_len)\n",
    "        loss = criterion(logits.view(-1, len(tag2id)), labels.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee78b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_tokens = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits.view(-1, len(tag2id)), labels.view(-1))\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy only on valid tokens (not -100)\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            mask = labels != -100\n",
    "            \n",
    "            correct_tokens += (predictions[mask] == labels[mask]).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "            \n",
    "    return total_loss / len(loader), correct_tokens / total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14324464",
   "metadata": {},
   "source": [
    "*Epochs:* Transformer models converge very quickly on small datasets like CONLL-03. Hence only *3 epochs* were used to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dcd924ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda...\n",
      "Epoch 1/3 | Train Loss: 0.1793 | Valid Loss: 0.0812 | Valid Token Acc: 0.9748\n",
      "Epoch 2/3 | Train Loss: 0.0541 | Valid Loss: 0.0689 | Valid Token Acc: 0.9802\n",
      "Epoch 3/3 | Train Loss: 0.0309 | Valid Loss: 0.0623 | Valid Token Acc: 0.9822\n"
     ]
    }
   ],
   "source": [
    "#Run Training\n",
    "epochs = 3\n",
    "print(f\"Starting training on {device}...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(bert_model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(bert_model, valid_loader, criterion)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Valid Loss: {valid_loss:.4f} | \"\n",
    "          f\"Valid Token Acc: {valid_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd38c8",
   "metadata": {},
   "source": [
    "### 3.3 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cae7aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model SAVED!\n"
     ]
    }
   ],
   "source": [
    "bert_save_path = f'{output_dir}/bert_ner_model.pt'\n",
    "\n",
    "torch.save(bert_model.state_dict(), bert_save_path)\n",
    "print(\"BERT model SAVED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333ca7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702a8f2",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18b8a0",
   "metadata": {},
   "source": [
    "### 4.1 Load Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9f46ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and ready for testing!\n"
     ]
    }
   ],
   "source": [
    "load_path = 'model_checkpoints/lstm_ner_model.pt'\n",
    "loaded_lstm = LSTM_NER(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, DROPOUT).to(device)\n",
    "loaded_lstm.load_state_dict(torch.load(load_path, map_location=device))\n",
    "\n",
    "loaded_lstm.eval() #to turn of dropouts\n",
    "print(\"Model loaded and ready for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "749de54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#LOAD BERT MODEL\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"  # #force transformers to use local cache only\n",
    "\n",
    "\n",
    "checkpoint = 'distilbert-base-cased' \n",
    "loaded_modelbr = BERT_NER(checkpoint, num_tags=len(tag2id)).to(device)\n",
    "\n",
    "load_pathbrt = 'model_checkpoints/bert_ner_model.pt'\n",
    "loaded_modelbr.load_state_dict(torch.load(load_pathbrt, map_location=device))\n",
    "loaded_modelbr.eval() #to turn off drop outs\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79565c97",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96bbcd",
   "metadata": {},
   "source": [
    "In Named Entity Recognition, *Token Accuracy* is often a poor metric because the vast majority of tokens are 'O'. A model that predicts 'O' for every token can easily achieve >80% accuracy while having 0% utility.\n",
    "\n",
    "* **Precision:** Of all the entities the model predicted, how many were correct?\n",
    "* **Recall:** Of all the entities in the ground truth, how many did the model find?\n",
    "* **F1-Score:** The harmonic mean of Precision and Recall.\n",
    "\n",
    "\n",
    "To calculate these metrics, A helper function was used to convert a list of IOB tags (e.g., `['B-PER', 'I-PER', 'O']`) into a set of discrete entities (e.g., `('PER', start_index, end_index)`).Outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eca2cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_from_tags(tag_sequence):\n",
    "    \"\"\"\n",
    "    Parses a sequence of IOB tags and extracts the entities.\n",
    "    Returns: A set of (entity_type, start_index, end_index) tuples.\n",
    "    \"\"\"\n",
    "    entities = set()\n",
    "    prev_tag = 'O'\n",
    "    prev_type = ''\n",
    "    start_idx = -1\n",
    "    \n",
    "    for i, tag in enumerate(tag_sequence):\n",
    "        # Extract the type (e.g., \"PER\") if the tag is not \"O\"\n",
    "        curr_type = tag.split('-')[1] if '-' in tag else ''\n",
    "        \n",
    "        # Check if an entity ended at the previous token\n",
    "        # Condition: Previous was an entity AND (Current is O OR Current starts new entity OR Current type mismatch)\n",
    "        if prev_tag != 'O' and (tag == 'O' or tag.startswith('B-') or curr_type != prev_type):\n",
    "            entities.add((prev_type, start_idx, i - 1))\n",
    "            \n",
    "        # Check if a new entity starts at the current token\n",
    "        if tag.startswith('B-'):\n",
    "            start_idx = i\n",
    "            prev_type = curr_type\n",
    "        # Handle cases where I- tag starts a sequence (broken IOB)\n",
    "        elif tag.startswith('I-'):\n",
    "            if prev_tag == 'O' or curr_type != prev_type:\n",
    "                start_idx = i \n",
    "                prev_type = curr_type\n",
    "        # Reset if O\n",
    "        elif tag == 'O':\n",
    "            start_idx = -1\n",
    "            prev_type = ''\n",
    "\n",
    "        prev_tag = tag\n",
    "\n",
    "    # Catch any entity that goes until the very last token\n",
    "    if prev_tag != 'O':\n",
    "        entities.add((prev_type, start_idx, len(tag_sequence) - 1))\n",
    "        \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e012434",
   "metadata": {},
   "source": [
    "### 4.3 Implementing the Evaluation Loop\n",
    "The evaluation function `evaluate_ner_system` iterates through a given `DataLoader` (validation or test set) and performs two levels of analysis\n",
    "\n",
    "1.  *Token-Level:* Calculates standard accuracy by comparing every valid token prediction (ignoring `-100` padding).\n",
    "2.  *Entity-Level:* Uses the `extract_entities_from_tags` helper to identify full entity spans and computes Precision, Recall, and F1-Score based on the overlap between predicted and ground-truth entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3079211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ner_system(model, loader, id2tag, model_name=\"Model\"):\n",
    "    model.eval()\n",
    "    \n",
    "    # --- FIX START: Handle id2tag conversion safely ---\n",
    "    if isinstance(id2tag, list):\n",
    "        # Check if it's a list of strings ['O', 'B-PER'] or tuples [(0, 'O')]\n",
    "        if len(id2tag) > 0 and isinstance(id2tag[0], str):\n",
    "             # It's just strings -> Convert to dict using indices\n",
    "            id2tag = {i: tag for i, tag in enumerate(id2tag)}\n",
    "        else:\n",
    "            # It's tuples -> Convert directly\n",
    "            id2tag = dict(id2tag)\n",
    "    # --- FIX END ---\n",
    "    \n",
    "    metrics = {\"correct_tokens\": 0, \"total_tokens\": 0, \"tp\": 0, \"fp\": 0, \"fn\": 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            preds_list = preds.cpu().tolist()\n",
    "            labels_list = labels.cpu().tolist()\n",
    "            \n",
    "            for i in range(len(labels_list)):\n",
    "                clean_preds_ids = []\n",
    "                clean_labels_ids = []\n",
    "                \n",
    "                for p, l in zip(preds_list[i], labels_list[i]):\n",
    "                    if l != -100:\n",
    "                        clean_preds_ids.append(p)\n",
    "                        clean_labels_ids.append(l)\n",
    "                \n",
    "                # Token Metrics\n",
    "                for p, l in zip(clean_preds_ids, clean_labels_ids):\n",
    "                    if p == l: metrics[\"correct_tokens\"] += 1\n",
    "                    metrics[\"total_tokens\"] += 1\n",
    "                \n",
    "                # Entity Metrics\n",
    "                pred_tags = [id2tag.get(idx, 'O') for idx in clean_preds_ids]\n",
    "                gold_tags = [id2tag.get(idx, 'O') for idx in clean_labels_ids]\n",
    "                \n",
    "                pred_ents = extract_entities_from_tags(pred_tags)\n",
    "                gold_ents = extract_entities_from_tags(gold_tags)\n",
    "                \n",
    "                tp = len(pred_ents.intersection(gold_ents))\n",
    "                metrics[\"tp\"] += tp\n",
    "                metrics[\"fp\"] += len(pred_ents) - tp\n",
    "                metrics[\"fn\"] += len(gold_ents) - tp\n",
    "\n",
    "    # Calculate final scores\n",
    "    token_acc = (metrics[\"correct_tokens\"] / metrics[\"total_tokens\"]) * 100 if metrics[\"total_tokens\"] > 0 else 0\n",
    "    tp, fp, fn = metrics[\"tp\"], metrics[\"fp\"], metrics[\"fn\"]\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"name\": model_name,\n",
    "        \"token_acc\": token_acc,\n",
    "        \"precision\": precision * 100,\n",
    "        \"recall\": recall * 100,\n",
    "        \"f1\": f1 * 100,\n",
    "        \"tp\": tp, \"fp\": fp, \"fn\": fn\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122114b",
   "metadata": {},
   "source": [
    "### 4.4 Final Model Comparison\n",
    "\n",
    "1.  *Token Accuracy:* General classification performance (including non-entities).\n",
    "2.  *Entity Precision/Recall/F1:* The true measure of NER performance (detecting full names, locations, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "efb7c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "METRIC               | LSTM            | BERT            | Better Model\n",
      "======================================================================\n",
      "Token Accuracy       | 4.48%         | 96.87%         | BERT\n",
      "----------------------------------------------------------------------\n",
      "Entity Precision     | 1.71%         | 85.85%         | BERT\n",
      "Entity Recall        | 5.24%         | 89.15%         | BERT\n",
      "Entity F1 Score      | 2.58%         | 87.47%         | BERT\n",
      "======================================================================\n",
      "LSTM: Found 169 correct entities. Missed 3057. Hallucinated 9691.\n",
      "BERT: Found 5035 correct entities. Missed 613. Hallucinated 830.\n"
     ]
    }
   ],
   "source": [
    "lstm_res = evaluate_ner_system(loaded_lstm, test_loader, id2tag, \"LSTM\")\n",
    "bert_res = evaluate_ner_system(loaded_modelbr, test_loader, id2tag, \"BERT\")\n",
    "\n",
    "# print Comparison Table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"{'METRIC':<20} | {'LSTM':<15} | {'BERT':<15} | {'Better Model'}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Token Accuracy':<20} | {lstm_res['token_acc']:.2f}%{'':<8} | {bert_res['token_acc']:.2f}%{'':<8} | {'BERT' if bert_res['token_acc'] > lstm_res['token_acc'] else 'LSTM'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Entity Precision':<20} | {lstm_res['precision']:.2f}%{'':<8} | {bert_res['precision']:.2f}%{'':<8} | {'BERT' if bert_res['precision'] > lstm_res['precision'] else 'LSTM'}\")\n",
    "print(f\"{'Entity Recall':<20} | {lstm_res['recall']:.2f}%{'':<8} | {bert_res['recall']:.2f}%{'':<8} | {'BERT' if bert_res['recall'] > lstm_res['recall'] else 'LSTM'}\")\n",
    "print(f\"{'Entity F1 Score':<20} | {lstm_res['f1']:.2f}%{'':<8} | {bert_res['f1']:.2f}%{'':<8} | {'BERT' if bert_res['f1'] > lstm_res['f1'] else 'LSTM'}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"LSTM: Found {lstm_res['tp']} correct entities. Missed {lstm_res['fn']}. Hallucinated {lstm_res['fp']}.\")\n",
    "print(f\"BERT: Found {bert_res['tp']} correct entities. Missed {bert_res['fn']}. Hallucinated {bert_res['fp']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857983b",
   "metadata": {},
   "source": [
    "* **True Positives (TP):** Correctly identified entities.\n",
    "* **False Negatives (FN):** Entities the model missed.\n",
    "* **False Positives (FP):** the model invented an entity that doesn't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a17ab7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2a59a",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "A significant performance disparity is observed between the two architectures. The baseline LSTM model is vastly outperformed by the fine-tuned BERT model across all recorded metrics.\n",
    "\n",
    "* **LSTM Failure:** Extremely poor performance is exhibited by the LSTM, as indicated by a Token Accuracy of only 4.48% and an F1 score of 2.58%. It is noted that the model failed to converge properly, evidenced by the high number of false positives (9,691 entities). This suggests that the patterns required to distinguish entities from non-entities were not effectively learned from scratch by the simple recurrent architectures like Bi-LTSMs.\n",
    "\n",
    "* **BERT Success:** Robust results are demonstrated by the BERT model, achieving a Token Accuracy of 96.87% and an Entity based F1 score of 87.47%. A balanced performance between Precision (85.85%) and Recall (89.15%) was achieved, indicating that both the boundaries and the types of named entities were successfully captured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de56ae3",
   "metadata": {},
   "source": [
    "It is concluded that the pre trained Transformer architecture, with its attention mechanisms and contextual embeddings, is significantly more effective for this Named Entity Recognition task than the Bidirectional LSTM trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710593f1",
   "metadata": {},
   "source": [
    "### 5.1 What Happened to LTSM  and How we can Improve this? \n",
    "\n",
    "The main reason for the failure is likely that the  sub-word tokenizer (30,000+ tokens) and training embeddings from scratch on a relatively small dataset (14k sentences). The model simply doesn't see enough examples of each sub-word to learn a good vector representation for them. In order to improve the performance of LTSM based methods:\n",
    "\n",
    "1. Use Pre-trained Static Embeddings (GloVe or FastText): Instead of initializing  embedding layer with random numbers (which the model has to learn from zero) initialize it with *GloVe* or *FastText* vectors. These vectors are pre trained on billions of words (Wikipedia, Common Crawl). The model will immediately know the the context of the emmbedding even if they don't appear in the training set ( [https://aclanthology.org/D14-1162/](https://aclanthology.org/D14-1162/)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02add04b",
   "metadata": {},
   "source": [
    "2. The loss curves likely didn't flatten out. Training embeddings from scratch requires more time than fine-tuning BERT. Hence, increasing epochs and using a learning rate scheduler may improve the LTSM performa, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c934ebc",
   "metadata": {},
   "source": [
    "##### Work in progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "08f4e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lstm_model = LSTM_NER(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, DROPOUT).to(device)\n",
    "\n",
    "\n",
    "# Optimizer (Start high)\n",
    "optimizer_long = optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Scheduler\n",
    "# mode='min': reduce LR when the metric (val_loss) stops decreasing\n",
    "# factor=0.5: cut LR in half\n",
    "# patience=2: wait 2 epochs with no improvement before cutting\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_long, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "93bf63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Train Loss=18.2858 | Valid Loss=0.1852 | LR=2.5e-04\n",
      "Epoch 02: Train Loss=17.1059 | Valid Loss=0.1913 | LR=2.5e-04\n",
      "Epoch 03: Train Loss=16.5309 | Valid Loss=0.1914 | LR=1.3e-04\n",
      "Epoch 04: Train Loss=15.3384 | Valid Loss=0.1919 | LR=1.3e-04\n",
      "Epoch 05: Train Loss=15.0695 | Valid Loss=0.1912 | LR=1.3e-04\n",
      "Epoch 06: Train Loss=14.6938 | Valid Loss=0.1924 | LR=6.3e-05\n",
      "Epoch 07: Train Loss=14.3856 | Valid Loss=0.1913 | LR=6.3e-05\n",
      "Epoch 08: Train Loss=13.9516 | Valid Loss=0.1921 | LR=6.3e-05\n",
      "Epoch 09: Train Loss=13.7149 | Valid Loss=0.1922 | LR=3.1e-05\n",
      "Epoch 10: Train Loss=14.2054 | Valid Loss=0.1937 | LR=3.1e-05\n",
      "Epoch 11: Train Loss=13.8450 | Valid Loss=0.1935 | LR=3.1e-05\n",
      "Epoch 12: Train Loss=13.4517 | Valid Loss=0.1938 | LR=1.6e-05\n",
      "Epoch 13: Train Loss=13.0323 | Valid Loss=0.1940 | LR=1.6e-05\n",
      "Epoch 14: Train Loss=12.8674 | Valid Loss=0.1944 | LR=1.6e-05\n",
      "Epoch 15: Train Loss=13.5570 | Valid Loss=0.1945 | LR=7.8e-06\n",
      "Epoch 16: Train Loss=13.2044 | Valid Loss=0.1948 | LR=7.8e-06\n",
      "Epoch 17: Train Loss=13.1148 | Valid Loss=0.1945 | LR=7.8e-06\n",
      "Epoch 18: Train Loss=12.9983 | Valid Loss=0.1942 | LR=3.9e-06\n",
      "Epoch 19: Train Loss=12.7453 | Valid Loss=0.1944 | LR=3.9e-06\n",
      "Epoch 20: Train Loss=12.9822 | Valid Loss=0.1944 | LR=3.9e-06\n",
      "Loaded best model from training.\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    t_loss = train_step(lstm_model, train_loader, criterion, optimizer_long, device=device, report=0)\n",
    "    \n",
    "    # Validate\n",
    "    v_loss = eval_step(lstm_model, valid_loader, criterion, device=device)\n",
    "    \n",
    "    # the Scheduler\n",
    "    # This checks v_loss and lowers the learning rate if stuck\n",
    "    scheduler.step(v_loss)\n",
    "    \n",
    "    # Save history\n",
    "    train_losses.append(t_loss)\n",
    "    valid_losses.append(v_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if v_loss < best_val_loss:\n",
    "        best_val_loss = v_loss\n",
    "        torch.save(lstm_model.state_dict(), 'model_checkpoints/best_lstm_glove.pt')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}: Train Loss={t_loss:.4f} | Valid Loss={v_loss:.4f} | LR={optimizer_long.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "\n",
    "loaded_best_ltsm = lstm_model.load_state_dict(torch.load('model_checkpoints/best_lstm_glove.pt'))\n",
    "print(\"Loaded best model from training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba74fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
